{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPREHENSIVE DATA DIAGNOSIS\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "MODEL: Combined\n",
      "================================================================================\n",
      "\n",
      "Synthetic samples:\n",
      "  Shape: torch.Size([50, 5, 10, 50])\n",
      "  Mean: -1.3334\n",
      "  Std: 1.4504\n",
      "  Min: -4.5656\n",
      "  Max: 13.0277\n",
      "\n",
      "Normalization parameters:\n",
      "  mu shape: torch.Size([1, 1, 10])\n",
      "  sd shape: torch.Size([1, 1, 10])\n",
      "    Var 0: mu=-44.5473, sd=19.6076\n",
      "    Var 1: mu=264.4723, sd=143.5289\n",
      "    Var 2: mu=43.6924, sd=14.0836\n",
      "    Var 3: mu=1.0400, sd=0.8400\n",
      "    Var 4: mu=0.9334, sd=0.2054\n",
      "    Var 5: mu=0.0014, sd=0.0004\n",
      "    Var 6: mu=0.0016, sd=0.0006\n",
      "    Var 7: mu=0.0085, sd=0.0061\n",
      "    Var 8: mu=0.0015, sd=0.0005\n",
      "    Var 9: mu=0.0030, sd=0.0016\n",
      "\n",
      "Hypothesis testing:\n",
      "  ✗ Hypothesis 1: Data is NOT in standard normalized space\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (50) must match the size of tensor b (10) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 137\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m  4. If normalizations differ between models: This is a training data bug\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[43mdiagnose_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./synthetic_samples_fixed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 64\u001b[39m, in \u001b[36mdiagnose_samples\u001b[39m\u001b[34m(samples_dir)\u001b[39m\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  ✗ Hypothesis 1: Data is NOT in standard normalized space\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# Hypothesis 2: Data is in model's normalized space (using its mu/sd)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m synth_renorm = (\u001b[43msynth\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m.\u001b[49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m) / sd.view(\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m)\n\u001b[32m     65\u001b[39m synth_renorm_valid = synth_renorm[torch.isfinite(synth_renorm)]\n\u001b[32m     66\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Hypothesis 2: If we normalize using (x-mu)/sd:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (50) must match the size of tensor b (10) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def diagnose_samples(samples_dir: str):\n",
    "    \"\"\"Comprehensive diagnosis of what state the data is actually in.\"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"COMPREHENSIVE DATA DIAGNOSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    name_map = {\n",
    "        'combined': 'Combined',\n",
    "        'vae_only': 'VAE only',\n",
    "        '2d_traits': '2D traits',\n",
    "        'unconditional': 'Unconditional'\n",
    "    }\n",
    "    \n",
    "    real_data = None\n",
    "    \n",
    "    for filename in os.listdir(samples_dir):\n",
    "        if filename.endswith('_synthetic.pt'):\n",
    "            model_key = filename.replace('_synthetic.pt', '')\n",
    "            model_name = name_map.get(model_key, model_key)\n",
    "            \n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"MODEL: {model_name}\")\n",
    "            print(f\"{'='*80}\")\n",
    "            \n",
    "            # Load synthetic\n",
    "            synth_path = os.path.join(samples_dir, f\"{model_key}_synthetic.pt\")\n",
    "            synth = torch.load(synth_path, map_location='cpu').float()\n",
    "            \n",
    "            # Load normalization\n",
    "            norm_path = os.path.join(samples_dir, f\"{model_key}_normalization.pt\")\n",
    "            norm_data = torch.load(norm_path, map_location='cpu')\n",
    "            mu = norm_data['mean'].float()\n",
    "            sd = norm_data['std'].float()\n",
    "            \n",
    "            print(f\"\\nSynthetic samples:\")\n",
    "            print(f\"  Shape: {synth.shape}\")\n",
    "            synth_valid = synth[torch.isfinite(synth)]\n",
    "            print(f\"  Mean: {synth_valid.mean():.4f}\")\n",
    "            print(f\"  Std: {synth_valid.std():.4f}\")\n",
    "            print(f\"  Min: {synth_valid.min():.4f}\")\n",
    "            print(f\"  Max: {synth_valid.max():.4f}\")\n",
    "            \n",
    "            print(f\"\\nNormalization parameters:\")\n",
    "            print(f\"  mu shape: {mu.shape}\")\n",
    "            print(f\"  sd shape: {sd.shape}\")\n",
    "            for i in range(min(10, mu.shape[-1])):\n",
    "                print(f\"    Var {i}: mu={mu.flatten()[i]:.4f}, sd={sd.flatten()[i]:.4f}\")\n",
    "            \n",
    "            # Test different hypotheses\n",
    "            print(f\"\\nHypothesis testing:\")\n",
    "            \n",
    "            # Hypothesis 1: Data is in standard normalized space (mean=0, std=1)\n",
    "            if abs(synth_valid.mean()) < 0.5 and 0.5 < synth_valid.std() < 1.5:\n",
    "                print(f\"  ✓ Hypothesis 1: Data IS in standard normalized space\")\n",
    "            else:\n",
    "                print(f\"  ✗ Hypothesis 1: Data is NOT in standard normalized space\")\n",
    "            \n",
    "            # Hypothesis 2: Data is in model's normalized space (using its mu/sd)\n",
    "            synth_renorm = (synth - mu.view(1, 1, 1, -1)) / sd.view(1, 1, 1, -1)\n",
    "            synth_renorm_valid = synth_renorm[torch.isfinite(synth_renorm)]\n",
    "            print(f\"  Hypothesis 2: If we normalize using (x-mu)/sd:\")\n",
    "            print(f\"    Result mean: {synth_renorm_valid.mean():.4f}\")\n",
    "            print(f\"    Result std: {synth_renorm_valid.std():.4f}\")\n",
    "            if abs(synth_renorm_valid.mean()) < 0.5 and 0.5 < synth_renorm_valid.std() < 1.5:\n",
    "                print(f\"    ✓ This produces standard normalized space\")\n",
    "                print(f\"    → Conclusion: Data is ALREADY UNNORMALIZED (in physical space)\")\n",
    "            else:\n",
    "                print(f\"    ✗ This does NOT produce standard normalized space\")\n",
    "            \n",
    "            # Hypothesis 3: Data is unnormalized (in physical space)\n",
    "            synth_unnorm = synth * sd.view(1, 1, 1, -1) + mu.view(1, 1, 1, -1)\n",
    "            synth_unnorm_valid = synth_unnorm[torch.isfinite(synth_unnorm)]\n",
    "            print(f\"  Hypothesis 3: If we unnormalize using x*sd + mu:\")\n",
    "            print(f\"    Result mean: {synth_unnorm_valid.mean():.4f}\")\n",
    "            print(f\"    Result std: {synth_unnorm_valid.std():.4f}\")\n",
    "            print(f\"    Result range: [{synth_unnorm_valid.min():.4f}, {synth_unnorm_valid.max():.4f}]\")\n",
    "            \n",
    "            # Load real data if available\n",
    "            if real_data is None and model_key != 'unconditional':\n",
    "                real_path = os.path.join(samples_dir, f\"{model_key}_real.pt\")\n",
    "                if os.path.exists(real_path):\n",
    "                    real_data = torch.load(real_path, map_location='cpu').float()\n",
    "                    \n",
    "                    print(f\"\\n{'='*80}\")\n",
    "                    print(f\"REAL DATA (from {model_name})\")\n",
    "                    print(f\"{'='*80}\")\n",
    "                    print(f\"  Shape: {real_data.shape}\")\n",
    "                    real_valid = real_data[torch.isfinite(real_data)]\n",
    "                    print(f\"  Mean: {real_valid.mean():.4f}\")\n",
    "                    print(f\"  Std: {real_valid.std():.4f}\")\n",
    "                    print(f\"  Min: {real_valid.min():.4f}\")\n",
    "                    print(f\"  Max: {real_valid.max():.4f}\")\n",
    "                    \n",
    "                    print(f\"\\nHypothesis testing for real data:\")\n",
    "                    \n",
    "                    # Is real data normalized?\n",
    "                    if abs(real_valid.mean()) < 0.5 and 0.5 < real_valid.std() < 1.5:\n",
    "                        print(f\"  ✓ Real data appears to be in standard normalized space\")\n",
    "                    else:\n",
    "                        print(f\"  ✗ Real data is NOT in standard normalized space\")\n",
    "                    \n",
    "                    # Try unnormalizing real data\n",
    "                    real_unnorm = real_data * sd.view(1, 1, -1) + mu.view(1, 1, -1)\n",
    "                    real_unnorm_valid = real_unnorm[torch.isfinite(real_unnorm)]\n",
    "                    print(f\"  If we unnormalize real using x*sd + mu:\")\n",
    "                    print(f\"    Result mean: {real_unnorm_valid.mean():.4f}\")\n",
    "                    print(f\"    Result std: {real_unnorm_valid.std():.4f}\")\n",
    "                    print(f\"    Result range: [{real_unnorm_valid.min():.4f}, {real_unnorm_valid.max():.4f}]\")\n",
    "                    \n",
    "                    # Try normalizing real data\n",
    "                    real_norm = (real_data - mu.view(1, 1, -1)) / sd.view(1, 1, -1)\n",
    "                    real_norm_valid = real_norm[torch.isfinite(real_norm)]\n",
    "                    print(f\"  If we normalize real using (x-mu)/sd:\")\n",
    "                    print(f\"    Result mean: {real_norm_valid.mean():.4f}\")\n",
    "                    print(f\"    Result std: {real_norm_valid.std():.4f}\")\n",
    "                    if abs(real_norm_valid.mean()) < 0.5 and 0.5 < real_norm_valid.std() < 1.5:\n",
    "                        print(f\"    ✓ This produces standard normalized space\")\n",
    "                        print(f\"    → Conclusion: Real data is ALREADY UNNORMALIZED\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"FINAL DIAGNOSIS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(\"\\nBased on the analysis above, the data state is:\")\n",
    "    print(\"  [Check the hypothesis test results above]\")\n",
    "    print(\"\\nRecommended fixes:\")\n",
    "    print(\"  1. If synthetic is already unnormalized: Don't unnormalize again\")\n",
    "    print(\"  2. If real is already unnormalized: Don't unnormalize again\")\n",
    "    print(\"  3. If both are normalized: Unnormalize both before comparison\")\n",
    "    print(\"  4. If normalizations differ between models: This is a training data bug\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    diagnose_samples(\"./synthetic_samples_fixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MODEL OUTPUT DIAGNOSTIC\n",
      "================================================================================\n",
      "Device: cuda\n",
      "\n",
      "Model loaded successfully\n",
      "\n",
      "Training normalization parameters:\n",
      "  Shape: (1, 1, 10)\n",
      "  Mean (first 5): [-44.547268   264.4723      43.692436     1.040037     0.93340003]\n",
      "  Std (first 5): [ 19.607582   143.52885     14.083567     0.84001416   0.20537171]\n",
      "\n",
      "================================================================================\n",
      "GENERATING TEST SAMPLES\n",
      "================================================================================\n",
      "Generating 10 samples...\n",
      "\n",
      "Raw model output:\n",
      "  Shape: (10, 50, 10)\n",
      "  Mean: -1.890928\n",
      "  Std: 0.191723\n",
      "  Min: -2.478394\n",
      "  Max: -0.586174\n",
      "\n",
      "Per-variable statistics:\n",
      "  Variable 0: mean=-1.9094, std=0.1655, range=[-2.3727, -1.1870]\n",
      "  Variable 1: mean=-1.8998, std=0.1783, range=[-2.4030, -0.9842]\n",
      "  Variable 2: mean=-1.9301, std=0.1518, range=[-2.4339, -1.1244]\n",
      "  Variable 3: mean=-1.9377, std=0.1466, range=[-2.3955, -1.2402]\n",
      "  Variable 4: mean=-1.8898, std=0.1658, range=[-2.3737, -0.9920]\n",
      "\n",
      "================================================================================\n",
      "HYPOTHESIS 1: Is output in normalized space (mean~0, std~1)?\n",
      "================================================================================\n",
      "✗ NO - Output is NOT in normalized space\n",
      "  Mean=-1.8909 (should be ~0)\n",
      "  Std=0.1917 (should be ~1)\n",
      "  This is a BUG - model should output normalized data\n",
      "\n",
      "================================================================================\n",
      "HYPOTHESIS 2: What if we unnormalize using training params?\n",
      "================================================================================\n",
      "After unnormalizing (x*std + mean):\n",
      "  Mean: -7.3721\n",
      "  Std: 26.8119\n",
      "  Range: [-91.0693, 123.2150]\n",
      "\n",
      "Physical reasonability check:\n",
      "  WRF_TEMP (var 0): mean=-82.0°C (should be ~-47°C)\n",
      "  WRF_PRES (var 1): mean=-8.2 hPa (should be ~250 hPa)\n",
      "  WRF_RELH (var 2): mean=16.5% (should be ~43%)\n",
      "\n",
      "================================================================================\n",
      "HYPOTHESIS 3: Check diffusion schedule parameters\n",
      "================================================================================\n",
      "Diffusion parameters:\n",
      "  num_steps: 50\n",
      "  beta range: [0.000100, 0.500000]\n",
      "  alpha range: [0.000000, 0.999900]\n",
      "  alpha[0]: 0.999900 (should be ~1.0)\n",
      "  alpha[-1]: 0.000000 (should be ~0.0)\n",
      "\n",
      "================================================================================\n",
      "FINAL DIAGNOSIS\n",
      "================================================================================\n",
      "\n",
      "✗ Model output is BROKEN\n",
      "  The diffusion sampling is not completing properly\n",
      "  Possible issues:\n",
      "    1. Bug in synthesize() method\n",
      "    2. Wrong alpha/beta schedule\n",
      "    3. Model wasn't trained properly\n",
      "\n",
      "  FIX: Check the synthesize() method in main_model.py\n",
      "       The final output should have mean~0, std~1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import yaml\n",
    "from main_model import CSDI_PM25\n",
    "\n",
    "\n",
    "def diagnose_model_output():\n",
    "    \"\"\"\n",
    "    Diagnose what the model is actually outputting during synthesis.\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"MODEL OUTPUT DIAGNOSTIC\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Load one model\n",
    "    config_path = './config/base_conditional_combined.yaml'\n",
    "    ckpt_path = './wandb/run-20260119_161726-85mtveaj/files/diffusion-combined_20260119_161727/model_best_val.pth'\n",
    "    \n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Device: {device}\\n\")\n",
    "    \n",
    "    model = CSDI_PM25(config, device=device)\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(\"Model loaded successfully\\n\")\n",
    "    \n",
    "    # Load normalization params that were used during training\n",
    "    target_mean = np.load('target_mean.npy')\n",
    "    target_std = np.load('target_std.npy')\n",
    "    \n",
    "    print(\"Training normalization parameters:\")\n",
    "    print(f\"  Shape: {target_mean.shape}\")\n",
    "    print(f\"  Mean (first 5): {target_mean.flatten()[:5]}\")\n",
    "    print(f\"  Std (first 5): {target_std.flatten()[:5]}\")\n",
    "    \n",
    "    # Generate a small batch\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"GENERATING TEST SAMPLES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    batch_size = 10\n",
    "    print(f\"Generating {batch_size} samples...\\n\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model.synthesize(batch_size=batch_size)\n",
    "    \n",
    "    output_np = output.cpu().numpy()\n",
    "    \n",
    "    print(\"Raw model output:\")\n",
    "    print(f\"  Shape: {output_np.shape}\")\n",
    "    print(f\"  Mean: {output_np.mean():.6f}\")\n",
    "    print(f\"  Std: {output_np.std():.6f}\")\n",
    "    print(f\"  Min: {output_np.min():.6f}\")\n",
    "    print(f\"  Max: {output_np.max():.6f}\")\n",
    "    \n",
    "    # Check per-variable statistics\n",
    "    print(f\"\\nPer-variable statistics:\")\n",
    "    for d in range(min(output_np.shape[2], 5)):  # First 5 variables\n",
    "        var_data = output_np[:, :, d]\n",
    "        print(f\"  Variable {d}: mean={var_data.mean():.4f}, std={var_data.std():.4f}, range=[{var_data.min():.4f}, {var_data.max():.4f}]\")\n",
    "    \n",
    "    # Hypothesis 1: Is it normalized? (Should be mean~0, std~1)\n",
    "    print(f\"\\n\" + \"=\"*80)\n",
    "    print(\"HYPOTHESIS 1: Is output in normalized space (mean~0, std~1)?\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    is_normalized = abs(output_np.mean()) < 0.5 and 0.5 < output_np.std() < 1.5\n",
    "    \n",
    "    if is_normalized:\n",
    "        print(\"✓ YES - Output appears to be in normalized space\")\n",
    "        print(\"  This is CORRECT - model should output normalized data\")\n",
    "    else:\n",
    "        print(\"✗ NO - Output is NOT in normalized space\")\n",
    "        print(f\"  Mean={output_np.mean():.4f} (should be ~0)\")\n",
    "        print(f\"  Std={output_np.std():.4f} (should be ~1)\")\n",
    "        print(\"  This is a BUG - model should output normalized data\")\n",
    "    \n",
    "    # Hypothesis 2: Try unnormalizing with saved params\n",
    "    print(f\"\\n\" + \"=\"*80)\n",
    "    print(\"HYPOTHESIS 2: What if we unnormalize using training params?\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Convert to tensor for easier manipulation\n",
    "    output_tensor = torch.from_numpy(output_np)\n",
    "    target_mean_tensor = torch.from_numpy(target_mean).float().view(1, 1, -1)\n",
    "    target_std_tensor = torch.from_numpy(target_std).float().view(1, 1, -1)\n",
    "    \n",
    "    output_unnorm = output_tensor * target_std_tensor + target_mean_tensor\n",
    "    output_unnorm_np = output_unnorm.numpy()\n",
    "    \n",
    "    print(f\"After unnormalizing (x*std + mean):\")\n",
    "    print(f\"  Mean: {output_unnorm_np.mean():.4f}\")\n",
    "    print(f\"  Std: {output_unnorm_np.std():.4f}\")\n",
    "    print(f\"  Range: [{output_unnorm_np.min():.4f}, {output_unnorm_np.max():.4f}]\")\n",
    "    \n",
    "    # Check if these values are physically reasonable\n",
    "    print(f\"\\nPhysical reasonability check:\")\n",
    "    print(f\"  WRF_TEMP (var 0): mean={output_unnorm_np[:,:,0].mean():.1f}°C (should be ~-47°C)\")\n",
    "    print(f\"  WRF_PRES (var 1): mean={output_unnorm_np[:,:,1].mean():.1f} hPa (should be ~250 hPa)\")\n",
    "    print(f\"  WRF_RELH (var 2): mean={output_unnorm_np[:,:,2].mean():.1f}% (should be ~43%)\")\n",
    "    \n",
    "    # Hypothesis 3: Is the diffusion process broken?\n",
    "    print(f\"\\n\" + \"=\"*80)\n",
    "    print(\"HYPOTHESIS 3: Check diffusion schedule parameters\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"Diffusion parameters:\")\n",
    "    print(f\"  num_steps: {model.num_steps}\")\n",
    "    print(f\"  beta range: [{model.beta.min():.6f}, {model.beta.max():.6f}]\")\n",
    "    print(f\"  alpha range: [{model.alpha.min():.6f}, {model.alpha.max():.6f}]\")\n",
    "    print(f\"  alpha[0]: {model.alpha[0]:.6f} (should be ~1.0)\")\n",
    "    print(f\"  alpha[-1]: {model.alpha[-1]:.6f} (should be ~0.0)\")\n",
    "    \n",
    "    # Final diagnosis\n",
    "    print(f\"\\n\" + \"=\"*80)\n",
    "    print(\"FINAL DIAGNOSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if is_normalized:\n",
    "        print(\"\\n✓ Model output is CORRECT\")\n",
    "        print(\"  Your generation script should save this as-is (normalized)\")\n",
    "        print(\"  Then unnormalize during analysis using the saved params\")\n",
    "    else:\n",
    "        print(\"\\n✗ Model output is BROKEN\")\n",
    "        print(\"  The diffusion sampling is not completing properly\")\n",
    "        print(\"  Possible issues:\")\n",
    "        print(\"    1. Bug in synthesize() method\")\n",
    "        print(\"    2. Wrong alpha/beta schedule\")\n",
    "        print(\"    3. Model wasn't trained properly\")\n",
    "        print(\"\\n  FIX: Check the synthesize() method in main_model.py\")\n",
    "        print(\"       The final output should have mean~0, std~1\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    diagnose_model_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PROPER NORMALIZATION CHECK\n",
      "============================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "INITIALIZING DATALOADER\n",
      "================================================================================\n",
      "Config: ['WRF_TEMP', 'WRF_PRES', 'WRF_RELH', 'WRF_PHI', 'WRF_PHIS', 'WRF_QICE', 'WRF_QSNOW', 'WRF_QVAPOR', 'WRF_QCLOUD', 'WRF_QRAIN'], horizon=50, unconditional=False, type=combined\n",
      "Batch size: 32\n",
      "\n",
      "Loading target data...\n",
      "  Raw shape: (24769, 71, 10), NaN%: 23.23%\n",
      "  Trimmed to horizon: (24769, 50, 10)\n",
      "  Placeholders: 6401947 (51.69%)\n",
      "\n",
      "Creating data splits (before filtering)...\n",
      "  Initial splits - Train: 19815, Val: 2477, Test: 2477\n",
      "\n",
      "Loading conditioning data (type: combined)...\n",
      "  Crystals: 24769\n",
      "\n",
      "  Loading VAE embeddings to determine valid samples...\n",
      "  Loading VAE embeddings...\n",
      "    Matched: 21434/24769 (86.5%)\n",
      "  Filtering all data to crystals with VAE embeddings...\n",
      "    Keeping 21434/24769 crystals\n",
      "    After filtering - Train: 17162, Val: 2138, Test: 2134\n",
      "  Loading 2D traits...\n",
      "    Shape: (21434, 14)\n",
      "\n",
      "  Normalizing VAE embeddings...\n",
      "  Normalization: all 1071700 values normalized\n",
      "\n",
      "  Normalizing 2D traits...\n",
      "  Normalization: all 300076 values normalized\n",
      "  VAE embeddings: shape (21434, 50) (normalized)\n",
      "  2D traits: shape (21434, 14) (normalized)\n",
      "  Combined features: VAE + 2D, shape: (21434, 64)\n",
      "  Saved data_mean.npy and data_std.npy\n",
      "    (Both VAE and 2D traits normalized)\n",
      "\n",
      "Normalizing target data...\n",
      "  Normalization: all 10717000 values normalized\n",
      "  Saved target_mean.npy and target_std.npy\n",
      "  Final target shape: (21434, 50, 10)\n",
      "\n",
      "Final splits - Train: 17162, Val: 2138, Test: 2134\n",
      "\n",
      "Creating DataLoaders...\n",
      "================================================================================\n",
      "DATALOADER INITIALIZATION COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Collected data shapes:\n",
      "  Observed: torch.Size([17162, 10, 50])\n",
      "  Conditioning: torch.Size([17162, 64, 50])\n",
      "\n",
      "------------------------------------------------------------\n",
      "OBSERVED DATA (Target Variables)\n",
      "------------------------------------------------------------\n",
      "WRF_TEMP    : mean=-0.0100, std= 0.9934 ✓\n",
      "              Valid: 857979/858100 (100.0%)\n",
      "WRF_PRES    : mean=-0.0092, std= 0.9880 ✓\n",
      "              Valid: 858100/858100 (100.0%)\n",
      "WRF_RELH    : mean=-0.0033, std= 0.9969 ✓\n",
      "              Valid: 856981/858100 (99.9%)\n",
      "WRF_PHI     : mean=-0.0007, std= 0.8341 ✓\n",
      "              Valid: 857026/858100 (99.9%)\n",
      "WRF_PHIS    : mean=-0.0005, std= 0.9925 ✓\n",
      "              Valid: 858070/858100 (100.0%)\n",
      "WRF_QICE    : mean=-0.0014, std= 0.9832 ✓\n",
      "              Valid: 857962/858100 (100.0%)\n",
      "WRF_QSNOW   : mean=-0.0006, std= 0.9713 ✓\n",
      "              Valid: 857825/858100 (100.0%)\n",
      "WRF_QVAPOR  : mean=-0.0064, std= 0.9864 ✓\n",
      "              Valid: 856675/858100 (99.8%)\n",
      "WRF_QCLOUD  : mean=-0.0009, std= 0.9698 ✓\n",
      "              Valid: 858099/858100 (100.0%)\n",
      "WRF_QRAIN   : mean=-0.0009, std= 0.9821 ✓\n",
      "              Valid: 858071/858100 (100.0%)\n",
      "\n",
      "------------------------------------------------------------\n",
      "CONDITIONING DATA\n",
      "------------------------------------------------------------\n",
      "VAE_0       : mean= 0.0032, std= 0.9972 ✓\n",
      "VAE_1       : mean= 0.0026, std= 1.0055 ✓\n",
      "VAE_2       : mean=-0.0008, std= 1.0003 ✓\n",
      "VAE_3       : mean= 0.0034, std= 0.9980 ✓\n",
      "VAE_4       : mean= 0.0001, std= 0.9989 ✓\n",
      "VAE_5       : mean=-0.0038, std= 0.9988 ✓\n",
      "VAE_6       : mean=-0.0041, std= 0.9964 ✓\n",
      "VAE_7       : mean=-0.0045, std= 1.0024 ✓\n",
      "VAE_8       : mean=-0.0026, std= 0.9962 ✓\n",
      "VAE_9       : mean= 0.0064, std= 1.0011 ✓\n",
      "\n",
      "------------------------------------------------------------\n",
      "OVERALL STATISTICS\n",
      "------------------------------------------------------------\n",
      "\n",
      "Observed data (excluding placeholders):\n",
      "  Valid values: 8576788/8581000 (100.0%)\n",
      "  Mean: -0.0034\n",
      "  Std:  0.9709\n",
      "  ✓ PROPERLY NORMALIZED\n",
      "\n",
      "Conditioning data (excluding placeholders):\n",
      "  Valid values: 54874500/54918400 (99.9%)\n",
      "  Mean: 0.0004\n",
      "  Std:  0.9979\n",
      "  ✓ PROPERLY NORMALIZED\n",
      "\n",
      "------------------------------------------------------------\n",
      "SAVED NORMALIZATION PARAMETERS\n",
      "------------------------------------------------------------\n",
      "\n",
      "Target normalization (first 5 dims):\n",
      "  WRF_TEMP    : mean= -45.179, std=  20.774\n",
      "  WRF_PRES    : mean= 240.629, std= 142.982\n",
      "  WRF_RELH    : mean=  41.140, std=  15.942\n",
      "  WRF_PHI     : mean=   0.995, std=   0.754\n",
      "  WRF_PHIS    : mean=   0.893, std=   0.267\n",
      "\n",
      "Conditioning normalization (first 5 dims):\n",
      "  Dim  0: mean=   0.787, std=   0.710\n",
      "  Dim  1: mean=  -0.510, std=   0.533\n",
      "  Dim  2: mean=   0.753, std=   0.658\n",
      "  Dim  3: mean=   0.507, std=   0.940\n",
      "  Dim  4: mean=   0.641, std=   0.692\n",
      "\n",
      "============================================================\n",
      "NORMALIZATION CHECK COMPLETE\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Better normalization check that properly excludes placeholders.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from dataset_crystaltraj import get_dataloader\n",
    "\n",
    "def check_normalization_properly():\n",
    "    \"\"\"Check normalization while properly excluding placeholders.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PROPER NORMALIZATION CHECK\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    config = {\n",
    "        'model': {\n",
    "            'target_vars': ['WRF_TEMP', 'WRF_PRES', 'WRF_RELH', 'WRF_PHI', 'WRF_PHIS', \n",
    "                           'WRF_QICE', 'WRF_QSNOW', 'WRF_QVAPOR', 'WRF_QCLOUD', 'WRF_QRAIN'],\n",
    "            'horizon': 50,\n",
    "            'is_unconditional': False,\n",
    "            'conditioning_type': 'combined'\n",
    "        },\n",
    "        'wandb_run': {\n",
    "            'config': {\n",
    "                'batch_size': 32\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    loaders = get_dataloader(config, batch_size=32, shuffle=False)\n",
    "    \n",
    "    # Collect all training data\n",
    "    all_observed = []\n",
    "    all_conditioning = []\n",
    "    \n",
    "    for batch in loaders['train']:\n",
    "        all_observed.append(batch['observed_data'])\n",
    "        all_conditioning.append(batch['conditioning_data'])\n",
    "    \n",
    "    all_observed = torch.cat(all_observed, dim=0)\n",
    "    all_conditioning = torch.cat(all_conditioning, dim=0)\n",
    "    \n",
    "    print(f\"Collected data shapes:\")\n",
    "    print(f\"  Observed: {all_observed.shape}\")\n",
    "    print(f\"  Conditioning: {all_conditioning.shape}\")\n",
    "    \n",
    "    # Check observed data (target variables)\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"OBSERVED DATA (Target Variables)\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    placeholder = 0.0\n",
    "    tolerance = 1e-3\n",
    "    \n",
    "    for i, var_name in enumerate(config['model']['target_vars']):\n",
    "        # Get data for this variable across all samples and timesteps\n",
    "        var_data = all_observed[:, i, :].flatten()\n",
    "        \n",
    "        # Exclude placeholders\n",
    "        mask = torch.abs(var_data - placeholder) > tolerance\n",
    "        valid_data = var_data[mask]\n",
    "        \n",
    "        if len(valid_data) > 0:\n",
    "            mean = valid_data.mean().item()\n",
    "            std = valid_data.std().item()\n",
    "            \n",
    "            print(f\"{var_name:12s}: mean={mean:7.4f}, std={std:7.4f}\", end=\"\")\n",
    "            \n",
    "            # Check if normalized (mean ≈ 0, std ≈ 1)\n",
    "            if abs(mean) < 0.15 and 0.7 < std < 1.3:\n",
    "                print(\" ✓\")\n",
    "            else:\n",
    "                print(\" ⚠️\")\n",
    "                \n",
    "            print(f\"              Valid: {len(valid_data)}/{len(var_data)} ({100*len(valid_data)/len(var_data):.1f}%)\")\n",
    "        else:\n",
    "            print(f\"{var_name:12s}: No valid data\")\n",
    "    \n",
    "    # Check conditioning data\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"CONDITIONING DATA\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    # Check first 5 dimensions\n",
    "    for i in range(min(10, all_conditioning.shape[1])):\n",
    "        cond_data = all_conditioning[:, i, :].flatten()\n",
    "        \n",
    "        # Exclude placeholders\n",
    "        mask = torch.abs(cond_data - placeholder) > tolerance\n",
    "        valid_data = cond_data[mask]\n",
    "        \n",
    "        if len(valid_data) > 0:\n",
    "            mean = valid_data.mean().item()\n",
    "            std = valid_data.std().item()\n",
    "            \n",
    "            if i < 50:\n",
    "                label = f\"VAE_{i}\"\n",
    "            else:\n",
    "                label = f\"2D_{i-50}\"\n",
    "            \n",
    "            print(f\"{label:12s}: mean={mean:7.4f}, std={std:7.4f}\", end=\"\")\n",
    "            \n",
    "            if abs(mean) < 0.15 and 0.7 < std < 1.3:\n",
    "                print(\" ✓\")\n",
    "            else:\n",
    "                print(\" ⚠️\")\n",
    "    \n",
    "    # Overall statistics\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"OVERALL STATISTICS\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    # Observed data (excluding placeholders)\n",
    "    obs_flat = all_observed.flatten()\n",
    "    obs_mask = torch.abs(obs_flat - placeholder) > tolerance\n",
    "    obs_valid = obs_flat[obs_mask]\n",
    "    \n",
    "    if len(obs_valid) > 0:\n",
    "        obs_mean = obs_valid.mean().item()\n",
    "        obs_std = obs_valid.std().item()\n",
    "        obs_pct = 100 * len(obs_valid) / len(obs_flat)\n",
    "        \n",
    "        print(f\"\\nObserved data (excluding placeholders):\")\n",
    "        print(f\"  Valid values: {len(obs_valid)}/{len(obs_flat)} ({obs_pct:.1f}%)\")\n",
    "        print(f\"  Mean: {obs_mean:.4f}\")\n",
    "        print(f\"  Std:  {obs_std:.4f}\")\n",
    "        \n",
    "        if abs(obs_mean) < 0.15 and 0.7 < obs_std < 1.3:\n",
    "            print(\"  ✓ PROPERLY NORMALIZED\")\n",
    "        else:\n",
    "            print(\"  ⚠️ May need adjustment\")\n",
    "    \n",
    "    # Conditioning data (excluding placeholders)\n",
    "    cond_flat = all_conditioning.flatten()\n",
    "    cond_mask = torch.abs(cond_flat - placeholder) > tolerance\n",
    "    cond_valid = cond_flat[cond_mask]\n",
    "    \n",
    "    if len(cond_valid) > 0:\n",
    "        cond_mean = cond_valid.mean().item()\n",
    "        cond_std = cond_valid.std().item()\n",
    "        cond_pct = 100 * len(cond_valid) / len(cond_flat)\n",
    "        \n",
    "        print(f\"\\nConditioning data (excluding placeholders):\")\n",
    "        print(f\"  Valid values: {len(cond_valid)}/{len(cond_flat)} ({cond_pct:.1f}%)\")\n",
    "        print(f\"  Mean: {cond_mean:.4f}\")\n",
    "        print(f\"  Std:  {cond_std:.4f}\")\n",
    "        \n",
    "        if abs(cond_mean) < 0.15 and 0.7 < cond_std < 1.3:\n",
    "            print(\"  ✓ PROPERLY NORMALIZED\")\n",
    "        else:\n",
    "            print(\"  ⚠️ May need adjustment\")\n",
    "    \n",
    "    # Load and check saved normalization parameters\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"SAVED NORMALIZATION PARAMETERS\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    target_mean = np.load(\"target_mean.npy\")\n",
    "    target_std = np.load(\"target_std.npy\")\n",
    "    data_mean = np.load(\"data_mean.npy\")\n",
    "    data_std = np.load(\"data_std.npy\")\n",
    "    \n",
    "    print(f\"\\nTarget normalization (first 5 dims):\")\n",
    "    for i in range(min(5, target_mean.shape[2])):\n",
    "        var_name = config['model']['target_vars'][i]\n",
    "        print(f\"  {var_name:12s}: mean={target_mean[0,0,i]:8.3f}, std={target_std[0,0,i]:8.3f}\")\n",
    "    \n",
    "    print(f\"\\nConditioning normalization (first 5 dims):\")\n",
    "    for i in range(min(5, data_mean.shape[2])):\n",
    "        print(f\"  Dim {i:2d}: mean={data_mean[0,0,i]:8.3f}, std={data_std[0,0,i]:8.3f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"NORMALIZATION CHECK COMPLETE\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_normalization_properly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "KDE ANALYSIS OF GENERATED SAMPLES\n",
      "================================================================================\n",
      "\n",
      "Loading data...\n",
      "  Loading combined...\n",
      "    Synthetic shape: (50, 5, 10, 50)\n",
      "    Real shape: (50, 50, 10)\n",
      "    DEBUG: data shape=(50, 5, 10, 50), mean shape=(1, 1, 10), std shape=(1, 1, 10)\n",
      "    DEBUG: Broadcasting ((50, 5, 10, 50)) * ((1, 1, 10, 1)) + ((1, 1, 10, 1))\n",
      "    DEBUG: data shape=(50, 50, 10), mean shape=(1, 1, 10), std shape=(1, 1, 10)\n",
      "    DEBUG: Broadcasting ((50, 50, 10)) * ((1, 1, 10)) + ((1, 1, 10))\n",
      "    Unnormalized synthetic range: [-68.54, 1004.39]\n",
      "  Loading vae_only...\n",
      "    Synthetic shape: (50, 5, 10, 50)\n",
      "    Real shape: (50, 50, 10)\n",
      "    DEBUG: data shape=(50, 5, 10, 50), mean shape=(1, 1, 10), std shape=(1, 1, 10)\n",
      "    DEBUG: Broadcasting ((50, 5, 10, 50)) * ((1, 1, 10, 1)) + ((1, 1, 10, 1))\n",
      "    DEBUG: data shape=(50, 50, 10), mean shape=(1, 1, 10), std shape=(1, 1, 10)\n",
      "    DEBUG: Broadcasting ((50, 50, 10)) * ((1, 1, 10)) + ((1, 1, 10))\n",
      "    Unnormalized synthetic range: [-69.98, 994.06]\n",
      "  Loading 2d_traits...\n",
      "    Synthetic shape: (50, 5, 10, 50)\n",
      "    Real shape: (50, 50, 10)\n",
      "    DEBUG: data shape=(50, 5, 10, 50), mean shape=(1, 1, 10), std shape=(1, 1, 10)\n",
      "    DEBUG: Broadcasting ((50, 5, 10, 50)) * ((1, 1, 10, 1)) + ((1, 1, 10, 1))\n",
      "    DEBUG: data shape=(50, 50, 10), mean shape=(1, 1, 10), std shape=(1, 1, 10)\n",
      "    DEBUG: Broadcasting ((50, 50, 10)) * ((1, 1, 10)) + ((1, 1, 10))\n",
      "    Unnormalized synthetic range: [-69.81, 946.05]\n",
      "  Loading unconditional...\n",
      "    Synthetic shape: (50, 5, 10, 50)\n",
      "    DEBUG: data shape=(50, 5, 10, 50), mean shape=(1, 1, 10), std shape=(1, 1, 10)\n",
      "    DEBUG: Broadcasting ((50, 5, 10, 50)) * ((1, 1, 10, 1)) + ((1, 1, 10, 1))\n",
      "    Unnormalized synthetic range: [-72.10, 945.09]\n",
      "\n",
      "Computing statistics...\n",
      "  combined...\n",
      "  vae_only...\n",
      "  2d_traits...\n",
      "  unconditional...\n",
      "\n",
      "Generating KDE plots...\n",
      "  WRF_TEMP...\n",
      "  Saved: kde_analysis/kde_WRF_TEMP.png\n",
      "  WRF_PRES...\n",
      "  Saved: kde_analysis/kde_WRF_PRES.png\n",
      "  WRF_RELH...\n",
      "  Saved: kde_analysis/kde_WRF_RELH.png\n",
      "  WRF_PHI...\n",
      "  Saved: kde_analysis/kde_WRF_PHI.png\n",
      "  WRF_PHIS...\n",
      "  Saved: kde_analysis/kde_WRF_PHIS.png\n",
      "  WRF_QICE...\n",
      "  Saved: kde_analysis/kde_WRF_QICE.png\n",
      "  WRF_QSNOW...\n",
      "  Saved: kde_analysis/kde_WRF_QSNOW.png\n",
      "  WRF_QVAPOR...\n",
      "  Saved: kde_analysis/kde_WRF_QVAPOR.png\n",
      "  WRF_QCLOUD...\n",
      "  Saved: kde_analysis/kde_WRF_QCLOUD.png\n",
      "  WRF_QRAIN...\n",
      "  Saved: kde_analysis/kde_WRF_QRAIN.png\n",
      "\n",
      "Generating comparison plots...\n",
      "  Saved: kde_analysis/statistics_means.png\n",
      "  Saved: kde_analysis/statistics_stds.png\n",
      "\n",
      "Creating summary table...\n",
      "  Saved: kde_analysis/statistics_summary.txt\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Results saved to: kde_analysis/\n",
      "\n",
      "Generated files:\n",
      "  - kde_*.png: KDE plots for each variable\n",
      "  - statistics_means.png: Mean comparison across models\n",
      "  - statistics_stds.png: Std deviation comparison\n",
      "  - statistics_summary.txt: Detailed statistics table\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "KDE Analysis for Generated Samples\n",
    "\n",
    "This script:\n",
    "1. Loads all generated samples (normalized)\n",
    "2. Unnormalizes them to original scale\n",
    "3. Computes and plots KDEs for each variable\n",
    "4. Compares synthetic vs real distributions\n",
    "5. Provides statistical metrics\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from scipy.stats import wasserstein_distance, ks_2samp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Variable names for plotting\n",
    "VAR_NAMES = [\n",
    "    'WRF_TEMP', 'WRF_PRES', 'WRF_RELH', 'WRF_PHI', 'WRF_PHIS',\n",
    "    'WRF_QICE', 'WRF_QSNOW', 'WRF_QVAPOR', 'WRF_QCLOUD', 'WRF_QRAIN'\n",
    "]\n",
    "\n",
    "# Nice names for plotting\n",
    "VAR_NICE_NAMES = {\n",
    "    'WRF_TEMP': 'Temperature (°C)',\n",
    "    'WRF_PRES': 'Pressure (hPa)',\n",
    "    'WRF_RELH': 'Relative Humidity (%)',\n",
    "    'WRF_PHI': 'Geopotential Height (km)',\n",
    "    'WRF_PHIS': 'Surface Geopotential (km)',\n",
    "    'WRF_QICE': 'Ice Mixing Ratio (g/kg)',\n",
    "    'WRF_QSNOW': 'Snow Mixing Ratio (g/kg)',\n",
    "    'WRF_QVAPOR': 'Water Vapor (g/kg)',\n",
    "    'WRF_QCLOUD': 'Cloud Mixing Ratio (g/kg)',\n",
    "    'WRF_QRAIN': 'Rain Mixing Ratio (g/kg)'\n",
    "}\n",
    "\n",
    "\n",
    "def load_model_data(data_dir, model_name):\n",
    "    \"\"\"Load synthetic and real data for a model.\"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    \n",
    "    # Load synthetic samples\n",
    "    synthetic = torch.load(data_dir / f\"{model_name}_synthetic.pt\").numpy()\n",
    "    \n",
    "    # Load normalization parameters\n",
    "    norm_params = torch.load(data_dir / f\"{model_name}_normalization.pt\")\n",
    "    mean = norm_params['mean'].numpy()  # (1, 1, D)\n",
    "    std = norm_params['std'].numpy()    # (1, 1, D)\n",
    "    \n",
    "    # Load real data if available (not for unconditional)\n",
    "    real = None\n",
    "    if (data_dir / f\"{model_name}_real.pt\").exists():\n",
    "        real = torch.load(data_dir / f\"{model_name}_real.pt\").numpy()\n",
    "    \n",
    "    return synthetic, real, mean, std\n",
    "\n",
    "\n",
    "def unnormalize(data, mean, std):\n",
    "    \"\"\"\n",
    "    Unnormalize data.\n",
    "    \n",
    "    Args:\n",
    "        data: Normalized data\n",
    "              - Shape: (K, S, D, T) for synthetic conditional (from saved .pt files)\n",
    "              - Shape: (K, T, D) for real (from saved .pt files)\n",
    "        mean: (1, 1, D)\n",
    "        std: (1, 1, D)\n",
    "    \n",
    "    Returns:\n",
    "        Unnormalized data in original scale\n",
    "    \"\"\"\n",
    "    # Check the actual shape\n",
    "    print(f\"    DEBUG: data shape={data.shape}, mean shape={mean.shape}, std shape={std.shape}\")\n",
    "    \n",
    "    if data.ndim == 4:  # (K, S, D, T)\n",
    "        # D is the 3rd dimension (index 2)\n",
    "        K, S, D, T = data.shape\n",
    "        # Reshape mean/std to (1, 1, D, 1) for broadcasting\n",
    "        mean_broadcast = mean.reshape(1, 1, -1, 1)\n",
    "        std_broadcast = std.reshape(1, 1, -1, 1)\n",
    "    elif data.ndim == 3:  # (K, T, D)\n",
    "        # D is the last dimension\n",
    "        K, T, D = data.shape\n",
    "        # Reshape to (1, 1, D) for broadcasting\n",
    "        mean_broadcast = mean.reshape(1, 1, -1)\n",
    "        std_broadcast = std.reshape(1, 1, -1)\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected data shape: {data.shape}\")\n",
    "    \n",
    "    print(f\"    DEBUG: Broadcasting ({data.shape}) * ({std_broadcast.shape}) + ({mean_broadcast.shape})\")\n",
    "    return data * std_broadcast + mean_broadcast\n",
    "\n",
    "\n",
    "def compute_kde_stats(synthetic, real, var_idx, var_name, bandwidth='scott'):\n",
    "    \"\"\"\n",
    "    Compute KDE and distribution statistics.\n",
    "    \n",
    "    Args:\n",
    "        synthetic: (K, S, T, D) or flattened\n",
    "        real: (K, T, D) or flattened\n",
    "        var_idx: Index of variable\n",
    "        var_name: Name of variable\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of statistics\n",
    "    \"\"\"\n",
    "    # Flatten and extract variable\n",
    "    if synthetic.ndim == 4:  # (K, S, T, D)\n",
    "        synth_var = synthetic[:, :, :, var_idx].flatten()\n",
    "    else:\n",
    "        synth_var = synthetic.flatten()\n",
    "    \n",
    "    if real is not None:\n",
    "        if real.ndim == 3:  # (K, T, D)\n",
    "            real_var = real[:, :, var_idx].flatten()\n",
    "        else:\n",
    "            real_var = real.flatten()\n",
    "    else:\n",
    "        real_var = None\n",
    "    \n",
    "    # Remove any remaining NaNs or infs\n",
    "    synth_var = synth_var[np.isfinite(synth_var)]\n",
    "    if real_var is not None:\n",
    "        real_var = real_var[np.isfinite(real_var)]\n",
    "    \n",
    "    stats_dict = {\n",
    "        'var_name': var_name,\n",
    "        'synthetic': {\n",
    "            'mean': np.mean(synth_var),\n",
    "            'std': np.std(synth_var),\n",
    "            'median': np.median(synth_var),\n",
    "            'q25': np.percentile(synth_var, 25),\n",
    "            'q75': np.percentile(synth_var, 75),\n",
    "            'min': np.min(synth_var),\n",
    "            'max': np.max(synth_var),\n",
    "            'n_samples': len(synth_var)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if real_var is not None:\n",
    "        stats_dict['real'] = {\n",
    "            'mean': np.mean(real_var),\n",
    "            'std': np.std(real_var),\n",
    "            'median': np.median(real_var),\n",
    "            'q25': np.percentile(real_var, 25),\n",
    "            'q75': np.percentile(real_var, 75),\n",
    "            'min': np.min(real_var),\n",
    "            'max': np.max(real_var),\n",
    "            'n_samples': len(real_var)\n",
    "        }\n",
    "        \n",
    "        # Compute distribution distance metrics\n",
    "        try:\n",
    "            # Wasserstein distance (Earth Mover's Distance)\n",
    "            wd = wasserstein_distance(synth_var, real_var)\n",
    "            stats_dict['wasserstein_distance'] = wd\n",
    "            \n",
    "            # Kolmogorov-Smirnov test\n",
    "            ks_stat, ks_pval = ks_2samp(synth_var, real_var)\n",
    "            stats_dict['ks_statistic'] = ks_stat\n",
    "            stats_dict['ks_pvalue'] = ks_pval\n",
    "        except Exception as e:\n",
    "            print(f\"    Warning: Could not compute distance metrics for {var_name}: {e}\")\n",
    "    \n",
    "    return stats_dict, synth_var, real_var\n",
    "\n",
    "\n",
    "def plot_kde_comparison(models_data, var_idx, var_name, output_dir):\n",
    "    \"\"\"\n",
    "    Plot KDE comparison for one variable across all models.\n",
    "    \n",
    "    Args:\n",
    "        models_data: Dict mapping model_name -> (synthetic_unnorm, real_unnorm)\n",
    "        var_idx: Variable index\n",
    "        var_name: Variable name\n",
    "        output_dir: Where to save plot\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    model_names = ['combined', 'vae_only', '2d_traits', 'unconditional']\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "    \n",
    "    for idx, (model_name, ax) in enumerate(zip(model_names, axes)):\n",
    "        if model_name not in models_data:\n",
    "            ax.axis('off')\n",
    "            continue\n",
    "        \n",
    "        synthetic_unnorm, real_unnorm = models_data[model_name]\n",
    "        \n",
    "        # Extract variable and flatten\n",
    "        if synthetic_unnorm.ndim == 4:  # (K, S, T, D)\n",
    "            synth_var = synthetic_unnorm[:, :, :, var_idx].flatten()\n",
    "        else:\n",
    "            synth_var = synthetic_unnorm[:, :, var_idx].flatten()\n",
    "        \n",
    "        synth_var = synth_var[np.isfinite(synth_var)]\n",
    "        \n",
    "        # Plot synthetic KDE\n",
    "        try:\n",
    "            kde_synth = stats.gaussian_kde(synth_var, bw_method='scott')\n",
    "            x_range = np.linspace(synth_var.min(), synth_var.max(), 200)\n",
    "            ax.plot(x_range, kde_synth(x_range), color=colors[idx], \n",
    "                   linewidth=2, label='Synthetic', alpha=0.8)\n",
    "            ax.fill_between(x_range, kde_synth(x_range), alpha=0.3, color=colors[idx])\n",
    "        except Exception as e:\n",
    "            print(f\"    Warning: Could not plot KDE for {model_name}/{var_name}: {e}\")\n",
    "        \n",
    "        # Plot real KDE if available\n",
    "        if real_unnorm is not None:\n",
    "            if real_unnorm.ndim == 3:  # (K, T, D)\n",
    "                real_var = real_unnorm[:, :, var_idx].flatten()\n",
    "            else:\n",
    "                real_var = real_unnorm[:, :, var_idx].flatten()\n",
    "            \n",
    "            real_var = real_var[np.isfinite(real_var)]\n",
    "            \n",
    "            try:\n",
    "                kde_real = stats.gaussian_kde(real_var, bw_method='scott')\n",
    "                x_range_real = np.linspace(real_var.min(), real_var.max(), 200)\n",
    "                ax.plot(x_range_real, kde_real(x_range_real), 'k--', \n",
    "                       linewidth=2, label='Real', alpha=0.6)\n",
    "            except Exception as e:\n",
    "                print(f\"    Warning: Could not plot real KDE for {model_name}/{var_name}: {e}\")\n",
    "        \n",
    "        # Formatting\n",
    "        ax.set_xlabel(VAR_NICE_NAMES.get(var_name, var_name), fontsize=11)\n",
    "        ax.set_ylabel('Density', fontsize=11)\n",
    "        ax.set_title(f'{model_name.replace(\"_\", \" \").title()}', fontsize=12, fontweight='bold')\n",
    "        ax.legend(fontsize=10)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    plt.suptitle(f'KDE Comparison: {VAR_NICE_NAMES.get(var_name, var_name)}', \n",
    "                 fontsize=14, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    output_path = Path(output_dir) / f'kde_{var_name}.png'\n",
    "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"  Saved: {output_path}\")\n",
    "\n",
    "\n",
    "def plot_statistics_comparison(all_stats, output_dir):\n",
    "    \"\"\"Plot comparison of statistics across all models.\"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    \n",
    "    model_names = list(all_stats.keys())\n",
    "    \n",
    "    # 1. Mean comparison\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for var_idx, var_name in enumerate(VAR_NAMES):\n",
    "        ax = axes[var_idx]\n",
    "        \n",
    "        synth_means = []\n",
    "        real_means = []\n",
    "        labels = []\n",
    "        \n",
    "        for model_name in model_names:\n",
    "            if var_name in all_stats[model_name]:\n",
    "                stats_dict = all_stats[model_name][var_name]\n",
    "                synth_means.append(stats_dict['synthetic']['mean'])\n",
    "                labels.append(model_name)\n",
    "                \n",
    "                if 'real' in stats_dict:\n",
    "                    real_means.append(stats_dict['real']['mean'])\n",
    "        \n",
    "        x = np.arange(len(labels))\n",
    "        width = 0.35\n",
    "        \n",
    "        ax.bar(x - width/2, synth_means, width, label='Synthetic', alpha=0.8)\n",
    "        if real_means:\n",
    "            ax.bar(x + width/2, [real_means[0]]*len(labels), width, \n",
    "                  label='Real', alpha=0.6, color='gray')\n",
    "        \n",
    "        ax.set_xlabel('Model', fontsize=9)\n",
    "        ax.set_ylabel('Mean', fontsize=9)\n",
    "        ax.set_title(VAR_NICE_NAMES.get(var_name, var_name), fontsize=10, fontweight='bold')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels([l.replace('_', '\\n') for l in labels], fontsize=8)\n",
    "        if var_idx == 0:\n",
    "            ax.legend(fontsize=8)\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.suptitle('Mean Values Comparison', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'statistics_means.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  Saved: {output_dir / 'statistics_means.png'}\")\n",
    "    \n",
    "    # 2. Standard deviation comparison\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for var_idx, var_name in enumerate(VAR_NAMES):\n",
    "        ax = axes[var_idx]\n",
    "        \n",
    "        synth_stds = []\n",
    "        real_stds = []\n",
    "        labels = []\n",
    "        \n",
    "        for model_name in model_names:\n",
    "            if var_name in all_stats[model_name]:\n",
    "                stats_dict = all_stats[model_name][var_name]\n",
    "                synth_stds.append(stats_dict['synthetic']['std'])\n",
    "                labels.append(model_name)\n",
    "                \n",
    "                if 'real' in stats_dict:\n",
    "                    real_stds.append(stats_dict['real']['std'])\n",
    "        \n",
    "        x = np.arange(len(labels))\n",
    "        width = 0.35\n",
    "        \n",
    "        ax.bar(x - width/2, synth_stds, width, label='Synthetic', alpha=0.8)\n",
    "        if real_stds:\n",
    "            ax.bar(x + width/2, [real_stds[0]]*len(labels), width, \n",
    "                  label='Real', alpha=0.6, color='gray')\n",
    "        \n",
    "        ax.set_xlabel('Model', fontsize=9)\n",
    "        ax.set_ylabel('Std Dev', fontsize=9)\n",
    "        ax.set_title(VAR_NICE_NAMES.get(var_name, var_name), fontsize=10, fontweight='bold')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels([l.replace('_', '\\n') for l in labels], fontsize=8)\n",
    "        if var_idx == 0:\n",
    "            ax.legend(fontsize=8)\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.suptitle('Standard Deviation Comparison', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'statistics_stds.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  Saved: {output_dir / 'statistics_stds.png'}\")\n",
    "\n",
    "\n",
    "def create_summary_table(all_stats, output_dir):\n",
    "    \"\"\"Create a text summary table of all statistics.\"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    \n",
    "    with open(output_dir / 'statistics_summary.txt', 'w') as f:\n",
    "        f.write(\"=\"*100 + \"\\n\")\n",
    "        f.write(\"DISTRIBUTION STATISTICS SUMMARY\\n\")\n",
    "        f.write(\"=\"*100 + \"\\n\\n\")\n",
    "        \n",
    "        for model_name, model_stats in all_stats.items():\n",
    "            f.write(f\"\\n{'='*100}\\n\")\n",
    "            f.write(f\"MODEL: {model_name.upper()}\\n\")\n",
    "            f.write(f\"{'='*100}\\n\\n\")\n",
    "            \n",
    "            for var_name, stats_dict in model_stats.items():\n",
    "                f.write(f\"\\n{'-'*100}\\n\")\n",
    "                f.write(f\"{VAR_NICE_NAMES.get(var_name, var_name)}\\n\")\n",
    "                f.write(f\"{'-'*100}\\n\")\n",
    "                \n",
    "                # Synthetic stats\n",
    "                synth = stats_dict['synthetic']\n",
    "                f.write(f\"\\nSynthetic:\\n\")\n",
    "                f.write(f\"  Mean:     {synth['mean']:12.4f}\\n\")\n",
    "                f.write(f\"  Std:      {synth['std']:12.4f}\\n\")\n",
    "                f.write(f\"  Median:   {synth['median']:12.4f}\\n\")\n",
    "                f.write(f\"  Q25-Q75:  [{synth['q25']:10.4f}, {synth['q75']:10.4f}]\\n\")\n",
    "                f.write(f\"  Range:    [{synth['min']:10.4f}, {synth['max']:10.4f}]\\n\")\n",
    "                f.write(f\"  N:        {synth['n_samples']:12,}\\n\")\n",
    "                \n",
    "                # Real stats if available\n",
    "                if 'real' in stats_dict:\n",
    "                    real = stats_dict['real']\n",
    "                    f.write(f\"\\nReal:\\n\")\n",
    "                    f.write(f\"  Mean:     {real['mean']:12.4f}\\n\")\n",
    "                    f.write(f\"  Std:      {real['std']:12.4f}\\n\")\n",
    "                    f.write(f\"  Median:   {real['median']:12.4f}\\n\")\n",
    "                    f.write(f\"  Q25-Q75:  [{real['q25']:10.4f}, {real['q75']:10.4f}]\\n\")\n",
    "                    f.write(f\"  Range:    [{real['min']:10.4f}, {real['max']:10.4f}]\\n\")\n",
    "                    f.write(f\"  N:        {real['n_samples']:12,}\\n\")\n",
    "                    \n",
    "                    # Distance metrics\n",
    "                    if 'wasserstein_distance' in stats_dict:\n",
    "                        f.write(f\"\\nDistribution Metrics:\\n\")\n",
    "                        f.write(f\"  Wasserstein Distance: {stats_dict['wasserstein_distance']:12.6f}\\n\")\n",
    "                        f.write(f\"  KS Statistic:         {stats_dict['ks_statistic']:12.6f}\\n\")\n",
    "                        f.write(f\"  KS p-value:           {stats_dict['ks_pvalue']:12.6e}\\n\")\n",
    "                        \n",
    "                        # Interpretation\n",
    "                        if stats_dict['ks_pvalue'] > 0.05:\n",
    "                            f.write(f\"  → Distributions are similar (p > 0.05) ✓\\n\")\n",
    "                        else:\n",
    "                            f.write(f\"  → Distributions are different (p ≤ 0.05) ⚠️\\n\")\n",
    "    \n",
    "    print(f\"  Saved: {output_dir / 'statistics_summary.txt'}\")\n",
    "\n",
    "\n",
    "def analyze_all_models(data_dir='./synthetic_samples_test', output_dir='./kde_analysis'):\n",
    "    \"\"\"Main analysis function.\"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"KDE ANALYSIS OF GENERATED SAMPLES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    model_names = ['combined', 'vae_only', '2d_traits', 'unconditional']\n",
    "    \n",
    "    # Load all data\n",
    "    print(\"\\nLoading data...\")\n",
    "    models_data_norm = {}\n",
    "    models_data_unnorm = {}\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        print(f\"  Loading {model_name}...\")\n",
    "        synthetic_norm, real_norm, mean, std = load_model_data(data_dir, model_name)\n",
    "        \n",
    "        print(f\"    Synthetic shape: {synthetic_norm.shape}\")\n",
    "        if real_norm is not None:\n",
    "            print(f\"    Real shape: {real_norm.shape}\")\n",
    "        \n",
    "        # Unnormalize\n",
    "        synthetic_unnorm = unnormalize(synthetic_norm, mean, std)\n",
    "        real_unnorm = unnormalize(real_norm, mean, std) if real_norm is not None else None\n",
    "        \n",
    "        models_data_norm[model_name] = (synthetic_norm, real_norm)\n",
    "        models_data_unnorm[model_name] = (synthetic_unnorm, real_unnorm)\n",
    "        \n",
    "        print(f\"    Unnormalized synthetic range: [{np.nanmin(synthetic_unnorm):.2f}, {np.nanmax(synthetic_unnorm):.2f}]\")\n",
    "    \n",
    "    # Compute statistics for all models and variables\n",
    "    print(\"\\nComputing statistics...\")\n",
    "    all_stats = {}\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        print(f\"  {model_name}...\")\n",
    "        synthetic_unnorm, real_unnorm = models_data_unnorm[model_name]\n",
    "        \n",
    "        model_stats = {}\n",
    "        for var_idx, var_name in enumerate(VAR_NAMES):\n",
    "            stats_dict, synth_var, real_var = compute_kde_stats(\n",
    "                synthetic_unnorm, real_unnorm, var_idx, var_name\n",
    "            )\n",
    "            model_stats[var_name] = stats_dict\n",
    "        \n",
    "        all_stats[model_name] = model_stats\n",
    "    \n",
    "    # Generate plots\n",
    "    print(\"\\nGenerating KDE plots...\")\n",
    "    for var_idx, var_name in enumerate(VAR_NAMES):\n",
    "        print(f\"  {var_name}...\")\n",
    "        plot_kde_comparison(models_data_unnorm, var_idx, var_name, output_dir)\n",
    "    \n",
    "    # Generate comparison plots\n",
    "    print(\"\\nGenerating comparison plots...\")\n",
    "    plot_statistics_comparison(all_stats, output_dir)\n",
    "    \n",
    "    # Create summary table\n",
    "    print(\"\\nCreating summary table...\")\n",
    "    create_summary_table(all_stats, output_dir)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANALYSIS COMPLETE\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nResults saved to: {output_dir}/\")\n",
    "    print(\"\\nGenerated files:\")\n",
    "    print(f\"  - kde_*.png: KDE plots for each variable\")\n",
    "    print(f\"  - statistics_means.png: Mean comparison across models\")\n",
    "    print(f\"  - statistics_stds.png: Std deviation comparison\")\n",
    "    print(f\"  - statistics_summary.txt: Detailed statistics table\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_all_models(\n",
    "        data_dir='./synthetic_samples_test',\n",
    "        output_dir='./kde_analysis'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "KDE ANALYSIS OF GENERATED SAMPLES\n",
      "================================================================================\n",
      "\n",
      "Loading data...\n",
      "  Loading combined...\n",
      "    Synthetic shape: (50, 5, 10, 50)\n",
      "    Real shape: (50, 50, 10)\n",
      "    DEBUG: data shape=(50, 5, 10, 50), mean shape=(1, 1, 10), std shape=(1, 1, 10)\n",
      "    DEBUG: Broadcasting ((50, 5, 10, 50)) * ((1, 1, 10, 1)) + ((1, 1, 10, 1))\n",
      "    DEBUG: data shape=(50, 50, 10), mean shape=(1, 1, 10), std shape=(1, 1, 10)\n",
      "    DEBUG: Broadcasting ((50, 50, 10)) * ((1, 1, 10)) + ((1, 1, 10))\n",
      "    Unnormalized synthetic range: [-68.54, 1004.39]\n",
      "  Loading vae_only...\n",
      "    Synthetic shape: (50, 5, 10, 50)\n",
      "    Real shape: (50, 50, 10)\n",
      "    DEBUG: data shape=(50, 5, 10, 50), mean shape=(1, 1, 10), std shape=(1, 1, 10)\n",
      "    DEBUG: Broadcasting ((50, 5, 10, 50)) * ((1, 1, 10, 1)) + ((1, 1, 10, 1))\n",
      "    DEBUG: data shape=(50, 50, 10), mean shape=(1, 1, 10), std shape=(1, 1, 10)\n",
      "    DEBUG: Broadcasting ((50, 50, 10)) * ((1, 1, 10)) + ((1, 1, 10))\n",
      "    Unnormalized synthetic range: [-69.98, 994.06]\n",
      "  Loading 2d_traits...\n",
      "    Synthetic shape: (50, 5, 10, 50)\n",
      "    Real shape: (50, 50, 10)\n",
      "    DEBUG: data shape=(50, 5, 10, 50), mean shape=(1, 1, 10), std shape=(1, 1, 10)\n",
      "    DEBUG: Broadcasting ((50, 5, 10, 50)) * ((1, 1, 10, 1)) + ((1, 1, 10, 1))\n",
      "    DEBUG: data shape=(50, 50, 10), mean shape=(1, 1, 10), std shape=(1, 1, 10)\n",
      "    DEBUG: Broadcasting ((50, 50, 10)) * ((1, 1, 10)) + ((1, 1, 10))\n",
      "    Unnormalized synthetic range: [-69.81, 946.05]\n",
      "  Loading unconditional...\n",
      "    Synthetic shape: (50, 5, 10, 50)\n",
      "    DEBUG: data shape=(50, 5, 10, 50), mean shape=(1, 1, 10), std shape=(1, 1, 10)\n",
      "    DEBUG: Broadcasting ((50, 5, 10, 50)) * ((1, 1, 10, 1)) + ((1, 1, 10, 1))\n",
      "    Unnormalized synthetic range: [-72.10, 945.09]\n",
      "\n",
      "Computing statistics...\n",
      "  combined...\n",
      "  vae_only...\n",
      "  2d_traits...\n",
      "  unconditional...\n",
      "\n",
      "Generating KDE plots...\n",
      "  WRF_TEMP...\n",
      "  Saved: kde_analysis/kde_WRF_TEMP.png\n",
      "  WRF_PRES...\n",
      "  Saved: kde_analysis/kde_WRF_PRES.png\n",
      "  WRF_RELH...\n",
      "  Saved: kde_analysis/kde_WRF_RELH.png\n",
      "  WRF_PHI...\n",
      "  Saved: kde_analysis/kde_WRF_PHI.png\n",
      "  WRF_PHIS...\n",
      "  Saved: kde_analysis/kde_WRF_PHIS.png\n",
      "  WRF_QICE...\n",
      "  Saved: kde_analysis/kde_WRF_QICE.png\n",
      "  WRF_QSNOW...\n",
      "  Saved: kde_analysis/kde_WRF_QSNOW.png\n",
      "  WRF_QVAPOR...\n",
      "  Saved: kde_analysis/kde_WRF_QVAPOR.png\n",
      "  WRF_QCLOUD...\n",
      "  Saved: kde_analysis/kde_WRF_QCLOUD.png\n",
      "  WRF_QRAIN...\n",
      "  Saved: kde_analysis/kde_WRF_QRAIN.png\n",
      "\n",
      "Generating comparison plots...\n",
      "  Saved: kde_analysis/statistics_means.png\n",
      "  Saved: kde_analysis/statistics_stds.png\n",
      "\n",
      "Creating summary table...\n",
      "  Saved: kde_analysis/statistics_summary.txt\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Results saved to: kde_analysis/\n",
      "\n",
      "Generated files:\n",
      "  - kde_*.png: KDE plots for each variable\n",
      "  - statistics_means.png: Mean comparison across models\n",
      "  - statistics_stds.png: Std deviation comparison\n",
      "  - statistics_summary.txt: Detailed statistics table\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "KDE Analysis for Generated Samples\n",
    "\n",
    "This script:\n",
    "1. Loads all generated samples (normalized)\n",
    "2. Unnormalizes them to original scale\n",
    "3. Computes and plots KDEs for each variable\n",
    "4. Compares synthetic vs real distributions\n",
    "5. Provides statistical metrics\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from scipy.stats import wasserstein_distance, ks_2samp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Variable names for plotting\n",
    "VAR_NAMES = [\n",
    "    'WRF_TEMP', 'WRF_PRES', 'WRF_RELH', 'WRF_PHI', 'WRF_PHIS',\n",
    "    'WRF_QICE', 'WRF_QSNOW', 'WRF_QVAPOR', 'WRF_QCLOUD', 'WRF_QRAIN'\n",
    "]\n",
    "\n",
    "# Nice names for plotting\n",
    "VAR_NICE_NAMES = {\n",
    "    'WRF_TEMP': 'Temperature (°C)',\n",
    "    'WRF_PRES': 'Pressure (hPa)',\n",
    "    'WRF_RELH': 'Relative Humidity (%)',\n",
    "    'WRF_PHI': 'Geopotential Height (km)',\n",
    "    'WRF_PHIS': 'Surface Geopotential (km)',\n",
    "    'WRF_QICE': 'Ice Mixing Ratio (g/kg)',\n",
    "    'WRF_QSNOW': 'Snow Mixing Ratio (g/kg)',\n",
    "    'WRF_QVAPOR': 'Water Vapor (g/kg)',\n",
    "    'WRF_QCLOUD': 'Cloud Mixing Ratio (g/kg)',\n",
    "    'WRF_QRAIN': 'Rain Mixing Ratio (g/kg)'\n",
    "}\n",
    "\n",
    "\n",
    "def load_model_data(data_dir, model_name):\n",
    "    \"\"\"Load synthetic and real data for a model.\"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    \n",
    "    # Load synthetic samples\n",
    "    synthetic = torch.load(data_dir / f\"{model_name}_synthetic.pt\").numpy()\n",
    "    \n",
    "    # Load normalization parameters\n",
    "    norm_params = torch.load(data_dir / f\"{model_name}_normalization.pt\")\n",
    "    mean = norm_params['mean'].numpy()  # (1, 1, D)\n",
    "    std = norm_params['std'].numpy()    # (1, 1, D)\n",
    "    \n",
    "    # Load real data if available (not for unconditional)\n",
    "    real = None\n",
    "    if (data_dir / f\"{model_name}_real.pt\").exists():\n",
    "        real = torch.load(data_dir / f\"{model_name}_real.pt\").numpy()\n",
    "    \n",
    "    return synthetic, real, mean, std\n",
    "\n",
    "\n",
    "def unnormalize(data, mean, std):\n",
    "    \"\"\"\n",
    "    Unnormalize data.\n",
    "    \n",
    "    Args:\n",
    "        data: Normalized data\n",
    "              - Shape: (K, S, D, T) for synthetic conditional (from saved .pt files)\n",
    "              - Shape: (K, T, D) for real (from saved .pt files)\n",
    "        mean: (1, 1, D)\n",
    "        std: (1, 1, D)\n",
    "    \n",
    "    Returns:\n",
    "        Unnormalized data in original scale\n",
    "    \"\"\"\n",
    "    # Check the actual shape\n",
    "    print(f\"    DEBUG: data shape={data.shape}, mean shape={mean.shape}, std shape={std.shape}\")\n",
    "    \n",
    "    if data.ndim == 4:  # (K, S, D, T)\n",
    "        # D is the 3rd dimension (index 2)\n",
    "        K, S, D, T = data.shape\n",
    "        # Reshape mean/std to (1, 1, D, 1) for broadcasting\n",
    "        mean_broadcast = mean.reshape(1, 1, -1, 1)\n",
    "        std_broadcast = std.reshape(1, 1, -1, 1)\n",
    "    elif data.ndim == 3:  # (K, T, D)\n",
    "        # D is the last dimension\n",
    "        K, T, D = data.shape\n",
    "        # Reshape to (1, 1, D) for broadcasting\n",
    "        mean_broadcast = mean.reshape(1, 1, -1)\n",
    "        std_broadcast = std.reshape(1, 1, -1)\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected data shape: {data.shape}\")\n",
    "    \n",
    "    print(f\"    DEBUG: Broadcasting ({data.shape}) * ({std_broadcast.shape}) + ({mean_broadcast.shape})\")\n",
    "    return data * std_broadcast + mean_broadcast\n",
    "\n",
    "\n",
    "def compute_kde_stats(synthetic, real, var_idx, var_name, bandwidth='scott'):\n",
    "    \"\"\"\n",
    "    Compute KDE and distribution statistics.\n",
    "    \n",
    "    Args:\n",
    "        synthetic: (K, S, T, D) or flattened\n",
    "        real: (K, T, D) or flattened\n",
    "        var_idx: Index of variable\n",
    "        var_name: Name of variable\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of statistics\n",
    "    \"\"\"\n",
    "    # Flatten and extract variable\n",
    "    # Synthetic shape: (K, S, D, T) where D is variables\n",
    "    # Real shape: (K, T, D) where D is variables\n",
    "    if synthetic.ndim == 4:  # (K, S, D, T)\n",
    "        synth_var = synthetic[:, :, var_idx, :].flatten()\n",
    "    else:\n",
    "        synth_var = synthetic.flatten()\n",
    "    \n",
    "    if real is not None:\n",
    "        if real.ndim == 3:  # (K, T, D)\n",
    "            real_var = real[:, :, var_idx].flatten()\n",
    "        else:\n",
    "            real_var = real.flatten()\n",
    "    else:\n",
    "        real_var = None\n",
    "    \n",
    "    # Remove any remaining NaNs or infs\n",
    "    synth_var = synth_var[np.isfinite(synth_var)]\n",
    "    if real_var is not None:\n",
    "        real_var = real_var[np.isfinite(real_var)]\n",
    "    \n",
    "    stats_dict = {\n",
    "        'var_name': var_name,\n",
    "        'synthetic': {\n",
    "            'mean': np.mean(synth_var),\n",
    "            'std': np.std(synth_var),\n",
    "            'median': np.median(synth_var),\n",
    "            'q25': np.percentile(synth_var, 25),\n",
    "            'q75': np.percentile(synth_var, 75),\n",
    "            'min': np.min(synth_var),\n",
    "            'max': np.max(synth_var),\n",
    "            'n_samples': len(synth_var)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if real_var is not None:\n",
    "        stats_dict['real'] = {\n",
    "            'mean': np.mean(real_var),\n",
    "            'std': np.std(real_var),\n",
    "            'median': np.median(real_var),\n",
    "            'q25': np.percentile(real_var, 25),\n",
    "            'q75': np.percentile(real_var, 75),\n",
    "            'min': np.min(real_var),\n",
    "            'max': np.max(real_var),\n",
    "            'n_samples': len(real_var)\n",
    "        }\n",
    "        \n",
    "        # Compute distribution distance metrics\n",
    "        try:\n",
    "            # Wasserstein distance (Earth Mover's Distance)\n",
    "            wd = wasserstein_distance(synth_var, real_var)\n",
    "            stats_dict['wasserstein_distance'] = wd\n",
    "            \n",
    "            # Kolmogorov-Smirnov test\n",
    "            ks_stat, ks_pval = ks_2samp(synth_var, real_var)\n",
    "            stats_dict['ks_statistic'] = ks_stat\n",
    "            stats_dict['ks_pvalue'] = ks_pval\n",
    "        except Exception as e:\n",
    "            print(f\"    Warning: Could not compute distance metrics for {var_name}: {e}\")\n",
    "    \n",
    "    return stats_dict, synth_var, real_var\n",
    "\n",
    "\n",
    "def plot_kde_comparison(models_data, var_idx, var_name, output_dir):\n",
    "    \"\"\"\n",
    "    Plot KDE comparison for one variable across all models.\n",
    "    \n",
    "    Args:\n",
    "        models_data: Dict mapping model_name -> (synthetic_unnorm, real_unnorm)\n",
    "        var_idx: Variable index\n",
    "        var_name: Variable name\n",
    "        output_dir: Where to save plot\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    model_names = ['combined', 'vae_only', '2d_traits', 'unconditional']\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "    \n",
    "    for idx, (model_name, ax) in enumerate(zip(model_names, axes)):\n",
    "        if model_name not in models_data:\n",
    "            ax.axis('off')\n",
    "            continue\n",
    "        \n",
    "        synthetic_unnorm, real_unnorm = models_data[model_name]\n",
    "        \n",
    "        # Extract variable and flatten\n",
    "        # Data shape is (K, S, D, T) where D is variables, T is time\n",
    "        if synthetic_unnorm.ndim == 4:  # (K, S, D, T)\n",
    "            synth_var = synthetic_unnorm[:, :, var_idx, :].flatten()\n",
    "        else:\n",
    "            synth_var = synthetic_unnorm[:, :, var_idx].flatten()\n",
    "        \n",
    "        synth_var = synth_var[np.isfinite(synth_var)]\n",
    "        \n",
    "        # Plot synthetic KDE\n",
    "        try:\n",
    "            kde_synth = stats.gaussian_kde(synth_var, bw_method='scott')\n",
    "            x_range = np.linspace(synth_var.min(), synth_var.max(), 200)\n",
    "            ax.plot(x_range, kde_synth(x_range), color=colors[idx], \n",
    "                   linewidth=2, label='Synthetic', alpha=0.8)\n",
    "            ax.fill_between(x_range, kde_synth(x_range), alpha=0.3, color=colors[idx])\n",
    "        except Exception as e:\n",
    "            print(f\"    Warning: Could not plot KDE for {model_name}/{var_name}: {e}\")\n",
    "        \n",
    "        # Plot real KDE if available\n",
    "        if real_unnorm is not None:\n",
    "            # Real shape is (K, T, D) where D is variables, T is time\n",
    "            if real_unnorm.ndim == 3:  # (K, T, D)\n",
    "                real_var = real_unnorm[:, :, var_idx].flatten()\n",
    "            else:\n",
    "                real_var = real_unnorm[:, :, var_idx].flatten()\n",
    "            \n",
    "            real_var = real_var[np.isfinite(real_var)]\n",
    "            \n",
    "            try:\n",
    "                kde_real = stats.gaussian_kde(real_var, bw_method='scott')\n",
    "                x_range_real = np.linspace(real_var.min(), real_var.max(), 200)\n",
    "                ax.plot(x_range_real, kde_real(x_range_real), 'k--', \n",
    "                       linewidth=2, label='Real', alpha=0.6)\n",
    "            except Exception as e:\n",
    "                print(f\"    Warning: Could not plot real KDE for {model_name}/{var_name}: {e}\")\n",
    "        \n",
    "        # Formatting\n",
    "        ax.set_xlabel(VAR_NICE_NAMES.get(var_name, var_name), fontsize=11)\n",
    "        ax.set_ylabel('Density', fontsize=11)\n",
    "        ax.set_title(f'{model_name.replace(\"_\", \" \").title()}', fontsize=12, fontweight='bold')\n",
    "        ax.legend(fontsize=10)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    plt.suptitle(f'KDE Comparison: {VAR_NICE_NAMES.get(var_name, var_name)}', \n",
    "                 fontsize=14, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    output_path = Path(output_dir) / f'kde_{var_name}.png'\n",
    "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"  Saved: {output_path}\")\n",
    "\n",
    "\n",
    "def plot_statistics_comparison(all_stats, output_dir):\n",
    "    \"\"\"Plot comparison of statistics across all models.\"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    \n",
    "    model_names = list(all_stats.keys())\n",
    "    \n",
    "    # 1. Mean comparison\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for var_idx, var_name in enumerate(VAR_NAMES):\n",
    "        ax = axes[var_idx]\n",
    "        \n",
    "        synth_means = []\n",
    "        real_means = []\n",
    "        labels = []\n",
    "        \n",
    "        for model_name in model_names:\n",
    "            if var_name in all_stats[model_name]:\n",
    "                stats_dict = all_stats[model_name][var_name]\n",
    "                synth_means.append(stats_dict['synthetic']['mean'])\n",
    "                labels.append(model_name)\n",
    "                \n",
    "                if 'real' in stats_dict:\n",
    "                    real_means.append(stats_dict['real']['mean'])\n",
    "        \n",
    "        x = np.arange(len(labels))\n",
    "        width = 0.35\n",
    "        \n",
    "        ax.bar(x - width/2, synth_means, width, label='Synthetic', alpha=0.8)\n",
    "        if real_means:\n",
    "            ax.bar(x + width/2, [real_means[0]]*len(labels), width, \n",
    "                  label='Real', alpha=0.6, color='gray')\n",
    "        \n",
    "        ax.set_xlabel('Model', fontsize=9)\n",
    "        ax.set_ylabel('Mean', fontsize=9)\n",
    "        ax.set_title(VAR_NICE_NAMES.get(var_name, var_name), fontsize=10, fontweight='bold')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels([l.replace('_', '\\n') for l in labels], fontsize=8)\n",
    "        if var_idx == 0:\n",
    "            ax.legend(fontsize=8)\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.suptitle('Mean Values Comparison', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'statistics_means.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  Saved: {output_dir / 'statistics_means.png'}\")\n",
    "    \n",
    "    # 2. Standard deviation comparison\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for var_idx, var_name in enumerate(VAR_NAMES):\n",
    "        ax = axes[var_idx]\n",
    "        \n",
    "        synth_stds = []\n",
    "        real_stds = []\n",
    "        labels = []\n",
    "        \n",
    "        for model_name in model_names:\n",
    "            if var_name in all_stats[model_name]:\n",
    "                stats_dict = all_stats[model_name][var_name]\n",
    "                synth_stds.append(stats_dict['synthetic']['std'])\n",
    "                labels.append(model_name)\n",
    "                \n",
    "                if 'real' in stats_dict:\n",
    "                    real_stds.append(stats_dict['real']['std'])\n",
    "        \n",
    "        x = np.arange(len(labels))\n",
    "        width = 0.35\n",
    "        \n",
    "        ax.bar(x - width/2, synth_stds, width, label='Synthetic', alpha=0.8)\n",
    "        if real_stds:\n",
    "            ax.bar(x + width/2, [real_stds[0]]*len(labels), width, \n",
    "                  label='Real', alpha=0.6, color='gray')\n",
    "        \n",
    "        ax.set_xlabel('Model', fontsize=9)\n",
    "        ax.set_ylabel('Std Dev', fontsize=9)\n",
    "        ax.set_title(VAR_NICE_NAMES.get(var_name, var_name), fontsize=10, fontweight='bold')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels([l.replace('_', '\\n') for l in labels], fontsize=8)\n",
    "        if var_idx == 0:\n",
    "            ax.legend(fontsize=8)\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.suptitle('Standard Deviation Comparison', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'statistics_stds.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  Saved: {output_dir / 'statistics_stds.png'}\")\n",
    "\n",
    "\n",
    "def create_summary_table(all_stats, output_dir):\n",
    "    \"\"\"Create a text summary table of all statistics.\"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    \n",
    "    with open(output_dir / 'statistics_summary.txt', 'w') as f:\n",
    "        f.write(\"=\"*100 + \"\\n\")\n",
    "        f.write(\"DISTRIBUTION STATISTICS SUMMARY\\n\")\n",
    "        f.write(\"=\"*100 + \"\\n\\n\")\n",
    "        \n",
    "        for model_name, model_stats in all_stats.items():\n",
    "            f.write(f\"\\n{'='*100}\\n\")\n",
    "            f.write(f\"MODEL: {model_name.upper()}\\n\")\n",
    "            f.write(f\"{'='*100}\\n\\n\")\n",
    "            \n",
    "            for var_name, stats_dict in model_stats.items():\n",
    "                f.write(f\"\\n{'-'*100}\\n\")\n",
    "                f.write(f\"{VAR_NICE_NAMES.get(var_name, var_name)}\\n\")\n",
    "                f.write(f\"{'-'*100}\\n\")\n",
    "                \n",
    "                # Synthetic stats\n",
    "                synth = stats_dict['synthetic']\n",
    "                f.write(f\"\\nSynthetic:\\n\")\n",
    "                f.write(f\"  Mean:     {synth['mean']:12.4f}\\n\")\n",
    "                f.write(f\"  Std:      {synth['std']:12.4f}\\n\")\n",
    "                f.write(f\"  Median:   {synth['median']:12.4f}\\n\")\n",
    "                f.write(f\"  Q25-Q75:  [{synth['q25']:10.4f}, {synth['q75']:10.4f}]\\n\")\n",
    "                f.write(f\"  Range:    [{synth['min']:10.4f}, {synth['max']:10.4f}]\\n\")\n",
    "                f.write(f\"  N:        {synth['n_samples']:12,}\\n\")\n",
    "                \n",
    "                # Real stats if available\n",
    "                if 'real' in stats_dict:\n",
    "                    real = stats_dict['real']\n",
    "                    f.write(f\"\\nReal:\\n\")\n",
    "                    f.write(f\"  Mean:     {real['mean']:12.4f}\\n\")\n",
    "                    f.write(f\"  Std:      {real['std']:12.4f}\\n\")\n",
    "                    f.write(f\"  Median:   {real['median']:12.4f}\\n\")\n",
    "                    f.write(f\"  Q25-Q75:  [{real['q25']:10.4f}, {real['q75']:10.4f}]\\n\")\n",
    "                    f.write(f\"  Range:    [{real['min']:10.4f}, {real['max']:10.4f}]\\n\")\n",
    "                    f.write(f\"  N:        {real['n_samples']:12,}\\n\")\n",
    "                    \n",
    "                    # Distance metrics\n",
    "                    if 'wasserstein_distance' in stats_dict:\n",
    "                        f.write(f\"\\nDistribution Metrics:\\n\")\n",
    "                        f.write(f\"  Wasserstein Distance: {stats_dict['wasserstein_distance']:12.6f}\\n\")\n",
    "                        f.write(f\"  KS Statistic:         {stats_dict['ks_statistic']:12.6f}\\n\")\n",
    "                        f.write(f\"  KS p-value:           {stats_dict['ks_pvalue']:12.6e}\\n\")\n",
    "                        \n",
    "                        # Interpretation\n",
    "                        if stats_dict['ks_pvalue'] > 0.05:\n",
    "                            f.write(f\"  → Distributions are similar (p > 0.05) ✓\\n\")\n",
    "                        else:\n",
    "                            f.write(f\"  → Distributions are different (p ≤ 0.05) ⚠️\\n\")\n",
    "    \n",
    "    print(f\"  Saved: {output_dir / 'statistics_summary.txt'}\")\n",
    "\n",
    "\n",
    "def analyze_all_models(data_dir='./synthetic_samples_test', output_dir='./kde_analysis'):\n",
    "    \"\"\"Main analysis function.\"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"KDE ANALYSIS OF GENERATED SAMPLES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    model_names = ['combined', 'vae_only', '2d_traits', 'unconditional']\n",
    "    \n",
    "    # Load all data\n",
    "    print(\"\\nLoading data...\")\n",
    "    models_data_norm = {}\n",
    "    models_data_unnorm = {}\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        print(f\"  Loading {model_name}...\")\n",
    "        synthetic_norm, real_norm, mean, std = load_model_data(data_dir, model_name)\n",
    "        \n",
    "        print(f\"    Synthetic shape: {synthetic_norm.shape}\")\n",
    "        if real_norm is not None:\n",
    "            print(f\"    Real shape: {real_norm.shape}\")\n",
    "        \n",
    "        # Unnormalize\n",
    "        synthetic_unnorm = unnormalize(synthetic_norm, mean, std)\n",
    "        real_unnorm = unnormalize(real_norm, mean, std) if real_norm is not None else None\n",
    "        \n",
    "        models_data_norm[model_name] = (synthetic_norm, real_norm)\n",
    "        models_data_unnorm[model_name] = (synthetic_unnorm, real_unnorm)\n",
    "        \n",
    "        print(f\"    Unnormalized synthetic range: [{np.nanmin(synthetic_unnorm):.2f}, {np.nanmax(synthetic_unnorm):.2f}]\")\n",
    "    \n",
    "    # Compute statistics for all models and variables\n",
    "    print(\"\\nComputing statistics...\")\n",
    "    all_stats = {}\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        print(f\"  {model_name}...\")\n",
    "        synthetic_unnorm, real_unnorm = models_data_unnorm[model_name]\n",
    "        \n",
    "        model_stats = {}\n",
    "        for var_idx, var_name in enumerate(VAR_NAMES):\n",
    "            stats_dict, synth_var, real_var = compute_kde_stats(\n",
    "                synthetic_unnorm, real_unnorm, var_idx, var_name\n",
    "            )\n",
    "            model_stats[var_name] = stats_dict\n",
    "        \n",
    "        all_stats[model_name] = model_stats\n",
    "    \n",
    "    # Generate plots\n",
    "    print(\"\\nGenerating KDE plots...\")\n",
    "    for var_idx, var_name in enumerate(VAR_NAMES):\n",
    "        print(f\"  {var_name}...\")\n",
    "        plot_kde_comparison(models_data_unnorm, var_idx, var_name, output_dir)\n",
    "    \n",
    "    # Generate comparison plots\n",
    "    print(\"\\nGenerating comparison plots...\")\n",
    "    plot_statistics_comparison(all_stats, output_dir)\n",
    "    \n",
    "    # Create summary table\n",
    "    print(\"\\nCreating summary table...\")\n",
    "    create_summary_table(all_stats, output_dir)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANALYSIS COMPLETE\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nResults saved to: {output_dir}/\")\n",
    "    print(\"\\nGenerated files:\")\n",
    "    print(f\"  - kde_*.png: KDE plots for each variable\")\n",
    "    print(f\"  - statistics_means.png: Mean comparison across models\")\n",
    "    print(f\"  - statistics_stds.png: Std deviation comparison\")\n",
    "    print(f\"  - statistics_summary.txt: Detailed statistics table\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_all_models(\n",
    "        data_dir='./synthetic_samples_test',\n",
    "        output_dir='./kde_analysis'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---- paste your results dict here ----\n",
    "results = {\n",
    "    \"crps\": {\n",
    "        \"normalized\": {\n",
    "            \"Unconditional\": {\n",
    "                \"global\": {\n",
    "                    \"mean\": 0.455703431609233,\n",
    "                    \"variance\": 0.3438329177007727\n",
    "                },\n",
    "                \"per_variable\": {\n",
    "                    \"mean\": {\n",
    "                        \"WRF_TEMP\": 0.5096260824362288,\n",
    "                        \"WRF_PRES\": 0.4395695622774767,\n",
    "                        \"WRF_RELH\": 0.49019994824486923,\n",
    "                        \"WRF_PHI\": 0.22738192745169078,\n",
    "                        \"WRF_PHIS\": 0.9351946365837736,\n",
    "                        \"WRF_QICE\": NaN,\n",
    "                        \"WRF_QSNOW\": NaN,\n",
    "                        \"WRF_QVAPOR\": NaN,\n",
    "                        \"WRF_QCLOUD\": NaN,\n",
    "                        \"WRF_QRAIN\": NaN\n",
    "                    },\n",
    "                    \"variance\": {\n",
    "                        \"WRF_TEMP\": 0.1906905688142736,\n",
    "                        \"WRF_PRES\": 0.5395076839447306,\n",
    "                        \"WRF_RELH\": 0.20997768019665505,\n",
    "                        \"WRF_PHI\": 0.3124788846628543,\n",
    "                        \"WRF_PHIS\": 8.227896343368474,\n",
    "                        \"WRF_QICE\": NaN,\n",
    "                        \"WRF_QSNOW\": NaN,\n",
    "                        \"WRF_QVAPOR\": NaN,\n",
    "                        \"WRF_QCLOUD\": NaN,\n",
    "                        \"WRF_QRAIN\": NaN\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"Combined\": {\n",
    "                \"global\": {\n",
    "                    \"mean\": 0.33918000741170284,\n",
    "                    \"variance\": 0.3318952141059212\n",
    "                },\n",
    "                \"per_variable\": {\n",
    "                    \"mean\": {\n",
    "                        \"WRF_TEMP\": 0.2972459089736422,\n",
    "                        \"WRF_PRES\": 0.303127531954899,\n",
    "                        \"WRF_RELH\": 0.45649683224786713,\n",
    "                        \"WRF_PHI\": 0.20656920967678336,\n",
    "                        \"WRF_PHIS\": 0.8880345891937982,\n",
    "                        \"WRF_QICE\": NaN,\n",
    "                        \"WRF_QSNOW\": NaN,\n",
    "                        \"WRF_QVAPOR\": NaN,\n",
    "                        \"WRF_QCLOUD\": NaN,\n",
    "                        \"WRF_QRAIN\": NaN\n",
    "                    },\n",
    "                    \"variance\": {\n",
    "                        \"WRF_TEMP\": 0.20316804931292368,\n",
    "                        \"WRF_PRES\": 0.4954027079631665,\n",
    "                        \"WRF_RELH\": 0.20458508362613612,\n",
    "                        \"WRF_PHI\": 0.29265388750953686,\n",
    "                        \"WRF_PHIS\": 8.458615798517402,\n",
    "                        \"WRF_QICE\": NaN,\n",
    "                        \"WRF_QSNOW\": NaN,\n",
    "                        \"WRF_QVAPOR\": NaN,\n",
    "                        \"WRF_QCLOUD\": NaN,\n",
    "                        \"WRF_QRAIN\": NaN\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"unnormalized\": {\n",
    "            \"Unconditional\": {\n",
    "                \"global\": {\n",
    "                    \"mean\": 24.307392536854348,\n",
    "                    \"variance\": 3980.6346510209146\n",
    "                },\n",
    "                \"per_variable\": {\n",
    "                    \"mean\": {\n",
    "                        \"WRF_TEMP\": 10.586785691423838,\n",
    "                        \"WRF_PRES\": 62.85041876850196,\n",
    "                        \"WRF_RELH\": 7.81457515932265,\n",
    "                        \"WRF_PHI\": 0.17148069797649954,\n",
    "                        \"WRF_PHIS\": 0.2499163029303237,\n",
    "                        \"WRF_QICE\": NaN,\n",
    "                        \"WRF_QSNOW\": NaN,\n",
    "                        \"WRF_QVAPOR\": NaN,\n",
    "                        \"WRF_QCLOUD\": NaN,\n",
    "                        \"WRF_QRAIN\": NaN\n",
    "                    },\n",
    "                    \"variance\": {\n",
    "                        \"WRF_TEMP\": 82.29134561445036,\n",
    "                        \"WRF_PRES\": 11029.574569532699,\n",
    "                        \"WRF_RELH\": 53.362646028294314,\n",
    "                        \"WRF_PHI\": 0.177721215058749,\n",
    "                        \"WRF_PHIS\": 0.5875894263679595,\n",
    "                        \"WRF_QICE\": NaN,\n",
    "                        \"WRF_QSNOW\": NaN,\n",
    "                        \"WRF_QVAPOR\": NaN,\n",
    "                        \"WRF_QCLOUD\": NaN,\n",
    "                        \"WRF_QRAIN\": NaN\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"Combined\": {\n",
    "                \"global\": {\n",
    "                    \"mean\": 16.99427657687965,\n",
    "                    \"variance\": 3370.282298559872\n",
    "                },\n",
    "                \"per_variable\": {\n",
    "                    \"mean\": {\n",
    "                        \"WRF_TEMP\": 6.174877708207189,\n",
    "                        \"WRF_PRES\": 43.3417005147448,\n",
    "                        \"WRF_RELH\": 7.277293313404588,\n",
    "                        \"WRF_PHI\": 0.15578473035573392,\n",
    "                        \"WRF_PHIS\": 0.23731350964145767,\n",
    "                        \"WRF_QICE\": NaN,\n",
    "                        \"WRF_QSNOW\": NaN,\n",
    "                        \"WRF_QVAPOR\": NaN,\n",
    "                        \"WRF_QCLOUD\": NaN,\n",
    "                        \"WRF_QRAIN\": NaN\n",
    "                    },\n",
    "                    \"variance\": {\n",
    "                        \"WRF_TEMP\": 87.67592580893309,\n",
    "                        \"WRF_PRES\": 10127.902293209856,\n",
    "                        \"WRF_RELH\": 51.99219931368879,\n",
    "                        \"WRF_PHI\": 0.1664458209263574,\n",
    "                        \"WRF_PHIS\": 0.6040660938714525,\n",
    "                        \"WRF_QICE\": NaN,\n",
    "                        \"WRF_QSNOW\": NaN,\n",
    "                        \"WRF_QVAPOR\": NaN,\n",
    "                        \"WRF_QCLOUD\": NaN,\n",
    "                        \"WRF_QRAIN\": NaN\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"variance\": {\n",
    "        \"normalized\": {\n",
    "            \"Unconditional\": {\n",
    "                \"global\": {\n",
    "                    \"mean\": 1.302576270455835,\n",
    "                    \"variance\": 66795.67286804893\n",
    "                },\n",
    "                \"per_variable\": {\n",
    "                    \"mean\": {\n",
    "                        \"WRF_TEMP\": 0.8381569862695308,\n",
    "                        \"WRF_PRES\": 0.7429375265225866,\n",
    "                        \"WRF_RELH\": 0.7683658694691656,\n",
    "                        \"WRF_PHI\": 2.868489754062307,\n",
    "                        \"WRF_PHIS\": 0.4900988649012914,\n",
    "                        \"WRF_QICE\": NaN,\n",
    "                        \"WRF_QSNOW\": NaN,\n",
    "                        \"WRF_QVAPOR\": NaN,\n",
    "                        \"WRF_QCLOUD\": NaN,\n",
    "                        \"WRF_QRAIN\": NaN\n",
    "                    },\n",
    "                    \"variance\": {\n",
    "                        \"WRF_TEMP\": 0.14837369097661918,\n",
    "                        \"WRF_PRES\": 0.20069064636267162,\n",
    "                        \"WRF_RELH\": 0.1225233211961902,\n",
    "                        \"WRF_PHI\": 267807.46165457397,\n",
    "                        \"WRF_PHIS\": 0.37525484555233135,\n",
    "                        \"WRF_QICE\": NaN,\n",
    "                        \"WRF_QSNOW\": NaN,\n",
    "                        \"WRF_QVAPOR\": NaN,\n",
    "                        \"WRF_QCLOUD\": NaN,\n",
    "                        \"WRF_QRAIN\": NaN\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"Combined\": {\n",
    "                \"global\": {\n",
    "                    \"mean\": 0.4181735781956309,\n",
    "                    \"variance\": 103.5704875001463\n",
    "                },\n",
    "                \"per_variable\": {\n",
    "                    \"mean\": {\n",
    "                        \"WRF_TEMP\": 0.3525519493908465,\n",
    "                        \"WRF_PRES\": 0.48805906916023234,\n",
    "                        \"WRF_RELH\": 0.6070444682986504,\n",
    "                        \"WRF_PHI\": 0.09186156503102837,\n",
    "                        \"WRF_PHIS\": 0.5671214404670987,\n",
    "                        \"WRF_QICE\": NaN,\n",
    "                        \"WRF_QSNOW\": NaN,\n",
    "                        \"WRF_QVAPOR\": NaN,\n",
    "                        \"WRF_QCLOUD\": NaN,\n",
    "                        \"WRF_QRAIN\": NaN\n",
    "                    },\n",
    "                    \"variance\": {\n",
    "                        \"WRF_TEMP\": 0.08096426058862939,\n",
    "                        \"WRF_PRES\": 0.469784958608979,\n",
    "                        \"WRF_RELH\": 0.14247130163740468,\n",
    "                        \"WRF_PHI\": 4.276453717188019,\n",
    "                        \"WRF_PHIS\": 577.6046809265014,\n",
    "                        \"WRF_QICE\": NaN,\n",
    "                        \"WRF_QSNOW\": NaN,\n",
    "                        \"WRF_QVAPOR\": NaN,\n",
    "                        \"WRF_QCLOUD\": NaN,\n",
    "                        \"WRF_QRAIN\": NaN\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"unnormalized\": {\n",
    "            \"Unconditional\": {\n",
    "                \"global\": {\n",
    "                    \"mean\": 3927.5237278310947,\n",
    "                    \"variance\": 63104421.64892162\n",
    "                },\n",
    "                \"per_variable\": {\n",
    "                    \"mean\": {\n",
    "                        \"WRF_TEMP\": 361.7014959104242,\n",
    "                        \"WRF_PRES\": 15188.44937254412,\n",
    "                        \"WRF_RELH\": 195.26853877345937,\n",
    "                        \"WRF_PHI\": 1.6314430155436663,\n",
    "                        \"WRF_PHIS\": 0.035000067029186316,\n",
    "                        \"WRF_QICE\": NaN,\n",
    "                        \"WRF_QSNOW\": NaN,\n",
    "                        \"WRF_QVAPOR\": NaN,\n",
    "                        \"WRF_QCLOUD\": NaN,\n",
    "                        \"WRF_QRAIN\": NaN\n",
    "                    },\n",
    "                    \"variance\": {\n",
    "                        \"WRF_TEMP\": 27631.646969330897,\n",
    "                        \"WRF_PRES\": 83878260.70430753,\n",
    "                        \"WRF_RELH\": 7913.109628165262,\n",
    "                        \"WRF_PHI\": 86628.31861429926,\n",
    "                        \"WRF_PHIS\": 0.0019138005175506226,\n",
    "                        \"WRF_QICE\": NaN,\n",
    "                        \"WRF_QSNOW\": NaN,\n",
    "                        \"WRF_QVAPOR\": NaN,\n",
    "                        \"WRF_QCLOUD\": NaN,\n",
    "                        \"WRF_QRAIN\": NaN\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"Combined\": {\n",
    "                \"global\": {\n",
    "                    \"mean\": 2123.015678328688,\n",
    "                    \"variance\": 56591451.73670605\n",
    "                },\n",
    "                \"per_variable\": {\n",
    "                    \"mean\": {\n",
    "                        \"WRF_TEMP\": 152.14162689064378,\n",
    "                        \"WRF_PRES\": 9977.770940509672,\n",
    "                        \"WRF_RELH\": 154.27114998884772,\n",
    "                        \"WRF_PHI\": 0.05224592782823873,\n",
    "                        \"WRF_PHIS\": 0.040500580294212496,\n",
    "                        \"WRF_QICE\": NaN,\n",
    "                        \"WRF_QSNOW\": NaN,\n",
    "                        \"WRF_QVAPOR\": NaN,\n",
    "                        \"WRF_QCLOUD\": NaN,\n",
    "                        \"WRF_QRAIN\": NaN\n",
    "                    },\n",
    "                    \"variance\": {\n",
    "                        \"WRF_TEMP\": 15077.982161072297,\n",
    "                        \"WRF_PRES\": 196345698.95179492,\n",
    "                        \"WRF_RELH\": 9201.440327584261,\n",
    "                        \"WRF_PHI\": 1.383314687585893,\n",
    "                        \"WRF_PHIS\": 2.945785112167575,\n",
    "                        \"WRF_QICE\": NaN,\n",
    "                        \"WRF_QSNOW\": NaN,\n",
    "                        \"WRF_QVAPOR\": NaN,\n",
    "                        \"WRF_QCLOUD\": NaN,\n",
    "                        \"WRF_QRAIN\": NaN\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"jsd\": {\n",
    "        \"Unconditional\": {\n",
    "            \"WRF_TEMP\": 0.08576902278743079,\n",
    "            \"WRF_PRES\": 0.2034697367766451,\n",
    "            \"WRF_RELH\": 0.015190060911810868,\n",
    "            \"WRF_PHI\": 0.4299411585190164,\n",
    "            \"WRF_PHIS\": 0.5649119930937401,\n",
    "            \"WRF_QICE\": NaN,\n",
    "            \"WRF_QSNOW\": NaN,\n",
    "            \"WRF_QVAPOR\": NaN,\n",
    "            \"WRF_QCLOUD\": NaN,\n",
    "            \"WRF_QRAIN\": NaN\n",
    "        },\n",
    "        \"Combined\": {\n",
    "            \"WRF_TEMP\": 0.03227201271672949,\n",
    "            \"WRF_PRES\": 0.13908606747024363,\n",
    "            \"WRF_RELH\": 0.006626244447357493,\n",
    "            \"WRF_PHI\": 0.031922824254363005,\n",
    "            \"WRF_PHIS\": 0.08828215123430269,\n",
    "            \"WRF_QICE\": NaN,\n",
    "            \"WRF_QSNOW\": NaN,\n",
    "            \"WRF_QVAPOR\": NaN,\n",
    "            \"WRF_QCLOUD\": NaN,\n",
    "            \"WRF_QRAIN\": NaN\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Choose which CRPS space to compare: \"normalized\" or \"unnormalized\"\n",
    "CRPS_SPACE = \"normalized\"\n",
    "\n",
    "# Variables you want in the plot (edit as needed)\n",
    "vars_to_plot = [\"WRF_TEMP\", \"WRF_PRES\", \"WRF_RELH\"]\n",
    "\n",
    "label_map = {\n",
    "    \"WRF_TEMP\": \"Temperature\",\n",
    "    \"WRF_PRES\": \"Pressure\",\n",
    "    \"WRF_RELH\": \"Relative Humidity\",\n",
    "}\n",
    "\n",
    "uncond = results[\"crps\"][CRPS_SPACE][\"Unconditional\"][\"per_variable\"][\"mean\"]\n",
    "cond   = results[\"crps\"][CRPS_SPACE][\"Combined\"][\"per_variable\"][\"mean\"]\n",
    "\n",
    "labels = []\n",
    "pct_improvement = []\n",
    "\n",
    "for v in vars_to_plot:\n",
    "    u = uncond.get(v, np.nan)\n",
    "    c = cond.get(v, np.nan)\n",
    "\n",
    "    # Skip NaNs or degenerate cases\n",
    "    if not np.isfinite(u) or not np.isfinite(c) or u == 0:\n",
    "        continue\n",
    "\n",
    "    pct = (u - c) / u * 100.0\n",
    "    pct_improvement.append(pct)\n",
    "    labels.append(label_map.get(v, v))\n",
    "\n",
    "# Sort bars from largest improvement to smallest\n",
    "order = np.argsort(pct_improvement)[::-1]\n",
    "pct_improvement = np.array(pct_improvement)[order]\n",
    "labels = np.array(labels)[order]\n",
    "\n",
    "plt.figure(figsize=(8, 4.5))\n",
    "plt.bar(labels, pct_improvement)\n",
    "plt.axhline(0, linewidth=1)\n",
    "plt.ylabel(\"Percent improvement in CRPS (%)\")\n",
    "plt.title(f\"Percent improvement: Conditional (Combined) vs Unconditional\\n({CRPS_SPACE.capitalize()} CRPS; higher is better)\")\n",
    "plt.xticks(rotation=20, ha=\"right\")\n",
    "\n",
    "# Annotate each bar with the numeric value\n",
    "for i, val in enumerate(pct_improvement):\n",
    "    plt.text(i, val + (0.8 if val >= 0 else -0.8), f\"{val:.1f}%\", ha=\"center\",\n",
    "             va=\"bottom\" if val >= 0 else \"top\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
